{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Approximation algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEMA IN COMPUTER SCIENCE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- problema $π$ è relazione: \n",
    "\t- $π \\subseteq I_{\\pi} x S_{\\pi}$ dove:\n",
    "\t    - $I$ = insieme delle istanze di input\n",
    "\t    - $S$ = insieme delle soluzioni al problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tipi problemi:\n",
    "\t- **decisione**: $S$ = $\\{true, false\\}$, controllano se data proprietà vale o no per un certo input.\n",
    "\t- **ricerca**: data un'istanza $x \\in I$, determinazione di una soluzione $Y \\in S$, tale che coppia $(x,y) \\in π$ appartiene a relazione che definisce problema. \n",
    "\t- **ottimizzazione**: data un'istanza $x \\in I$, determinazione di soluzione $Y \\in S$ che ottimizza data misura di funzione costo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità per algoritmi e problemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- espressa in funzione della cardinalità dell'input\n",
    "- cardinalità dell'input di $x$: \n",
    "    - quantità memoria necessaria per memorizzare $x$\n",
    "    - lunghezza della stringa che codifica $x$ in un particolare codice naturale $c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- codice naturale: \n",
    "\t- stringhe che codificano istanze non devono essere ridondanti o allungate inutilmente.\n",
    "\t- numeri espressi in base $ \\geq 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $t_A(x)$: running time di algoritmo $A$ su input $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- worst case running time di $A$: sia $t_A(x)$ il running time dell'algoritmo $A$ per input $X$, allora il worst case running time di $A$ è: $T_A(n)$ = $max${$t_A(x)$ | $|x| \\leq n$}, per ogni $n > 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un algoritmo A ha time complexity:\n",
    "\t- $O(g(n))$ se $T_A(n)$ = $O(g(n))$: $g(n)$ limite superiore \n",
    "\t- $Ω(g(n))$ se $T_A(n)$ = $Ω(g(n))$: $g(n)$ limite inferiore\n",
    "\t- $Θ(g(n))$ se $T_A(n)$ = $Θ(g(n))$: $g(n)$ limite stretto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un problema ha complessità:\n",
    "\t- $O(g(n))$: se esiste un algoritmo $A$ che lo risolve e ha complessità $O(g(n))$\n",
    "\t- $Ω(g(n))$: se ogni algoritmo $A$ che lo risolve ha complessità $Ω(g(n))$\n",
    "\t- $Θ(g(n))$: se ha complessità $O(g(n))$ e $Ω(g(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problemi di decisione e classi di complessità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- problemi di decisione sono descritti da istanza di input e una domanda sull'input.\n",
    "- in problemi di decisione $I = Y \\cup N$:\n",
    "    - $Y$: insieme istanza positive\n",
    "    - $N$: insieme istanze negative"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un algoritmo $A$ risolve $π$ SE E SOLO SE per ogni input $x \\in I$, $A$ risponde 1 SE E SOLO SE $x \\in Y$  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $TIME(g(n))$ = classe di problemi di decisione con complessità $O(g(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmi non-deterministici per problemi di decisione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 fasi:\n",
    "\t- fase 1: genera non-deterministicamente certificato $y$\n",
    "\t- fase 2: partendo da input $x$ e da certificato $y$, controlla se instanza $x$ è positiva."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un algoritmo non-deterministico $A$ risolve $π$ SE:\n",
    "\t- si ferma per ogni possibile certificato $y$ ed\n",
    "\t- esiste certificato $y$ per il quale $A$ risponde 1 SE E SOLO SE $x$ appartiene ad $Y$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Complessità**: costo fase 2, espressa come funzione sulla cardinalità dell'input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$NTIME(g(n))$: classe di problemi di decisione con complessità non-deterministica $O(g(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- algoritmo deterministico meno potente di non-deterministico (non può eseguire fase 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se c'è algoritmo deterministico $A$ che risolve $π$, c'è algoritmo non-deterministico $A'$ che risolve $π$ con la stessa complessità: esegue fase 1 e coincide con $A$ nella fase 2 ignorando certificato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$TIME(g(n)) \\subseteq NTIME(g(n))$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un problema è trattabile se è possibile risolverlo in modo efficiente (deterministico)(complessità delimitata da un polinomio della dimensione dell'input):\n",
    "\t- crescita funzioni polinomiali rispetto a funzioni esponenziali: esponenziale cresce rapidamente\n",
    "\t- robustezza concetto risolvibilità in tempo polinomiale: \n",
    "\t\t- indipendenza da codice naturale usato\n",
    "\t\t- indipendenza da modello computazionale adottato, se modello computazionale adottato è ragionevole (tali modelli sono relazionati polinomialmente, possono simularsi a vicenda in tempo polinomiale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Codici relazionati polinomialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 codici $c_1$ e $c_2$ per un problema $\\pi$ sono relazionati polinomialmente se esistono 2 polinomi $p_1$ e $p_2$ tale che $|X|_{c_1} \\leq p_1(|X|_{c_2})$ e $|X|_{c_2} \\leq p_2(|X|_{c_1})$\n",
    "- se complessità rispetto a $c_1$ è $O(q_1(|X|_{c_1}))$ allora rispetto a $c_2$ è $O(q_1(p_1(|X|_{c_2}))) = O(q_2(|X|_{c_2}))$\n",
    "dove $q_1$ polinomio e $q_2$ polinomio tale che $q_2(l) = q_1(p_1(l))$\n",
    "- quindi: 2 quantità sono relazionate polinomialmente se sono polinomi sulle stesse variabili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelli computazionali simulabili polinomialmente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 2 modelli computazionali $M_1$ ed $M_2$ sono mutualmente polinomialmente simulabili se esistono 2 polinomi $p_1$ e $p_2$ tali che:\n",
    "\t- ciascun algoritmo $A$ per $M_1$ con complessità $T_A(n)$ può essere simulato in $M2$ in tempo $p_1(T_A(n))$\n",
    "\t- ciascun algoritmo $A$ per $M_2$ con complessità $T_A(n)$ può essere simulato in $M1$ in tempo $p_2(T_A(n))$\n",
    "- se $A$ è polinomiale per $M_1$ allora è polinomiale per $M_2$ e viceversa\n",
    "- modelli computazionali ragionevoli sono mutualmente simulabli: risolvibiliità polinomiale non dipende da modello usato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classi P ed NP"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$P$ = classe di tutti i problemi risolvibili deterministicamente in tempo polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$NP$ = classe di tutti i problemi risolvibili non-deterministicamente in tempo polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemi NP-completi:\n",
    "- i più difficili di NP\n",
    "- se uno di loro appartiene a P, allora $P=NP$\n",
    "- congettura $P \\neq NP$: nessuno fino ad ora è riuscito a trovare un algoritmo polinomiale per un problema NP-completo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PROBLEMI DI OTTIMIZZAZIONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un **problema di ottimizzazione** $\\pi$ è $(I, S, m, goal)$ con:\n",
    " \t- $I$: insieme delle istanze di input di $\\pi$\n",
    " \t- $S(x)$: insieme delle soluzioni feasible dell'istanza $x \\in I$\n",
    " \t- $m(x,y)$: misura della soluzione $y \\in S(x)$ per input $x \\in I$\n",
    " \t- $goal$: {min, max} specifica se abbiamo problema di minimo o di massimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **soluzione ottima**: data un'istanza $x$ che appartiene ad $I$, una soluzione $y^*$ appartenente ad $S(x)$ è ottima per $x$ se $m(x, y^*)$ = $goal${$m(x,y)$ | $y \\in S(x)$}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la **misura della soluzione ottima** di $x$ è denotata come $m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problema di decisione sottostante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- tutti i problemi di ottimizzazione hanno un **problema di decisione sottostante**: introducendo intero $k$ all'istanza di input $x$ e chiedendo se esiste soluzione feasible che ha misura $ \\leq k$ (MIN) oppure $ \\geq k$ (MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **problema di ottimizzazione**: dato input $x$, trova $y$ appartente ad $S(x)$ tale che $m(x,y)$ soddisfi il $goal$\n",
    "- **problema di decisione sottostante**: dato un input $x$ ed un intero $k$, esiste soluzione feasible $y$ che abbia misura $ \\leq k $(MIN) o $ \\geq k$ (MAX) ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- SE esiste algoritmo polinomiale $A$ per problema di ottimizzazione, ALLORA esiste algoritmo polinomiale $A'$ per problema di decisione sottostante che lavora così:\n",
    "\t- esegue $A$ per determinare soluzione ottima $y^*$ per l'input $x$\n",
    "\t- risponde $1$ se $m(x,y^*) \\leq k$ (MIN) o se $m(x,y^*) \\geq k$ (MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- il problema di ottimizzazione è difficile **almeno quanto** il problema di decisione sottostante."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classi di complessità per problemi di ottimizzazione: PO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un **problema di ottimizzazione** $\\pi$ appartiene alla classe $PO$ se:\n",
    "\t- per ogni input $x$, $x \\in I$ può essere controllato in tempo polinomiale\n",
    "\t- esiste un polinomio $p$ tale che per ogni $x \\in I$ e $y \\in S(x)$, $|y| \\leq p(|x|)$\n",
    "\t- per ogni $x \\in I$ ed $y \\in S(x)$, $m(x,y)$ può essere computato in tempo polinomiale\n",
    "\t- per ogni $x \\in I$, una soluzione ottima $y^*$ può essere computata in tempo polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classi di complessità per problemi di ottimizzazione: NPO"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un **problema di ottimizzazione** $\\pi$ appartiene alla classe $NPO$ se:\n",
    "\t- tutto come sopra ma NON abbiamo: per ogni $x \\in I$, una soluzione ottima $y^*$ può essere computata in tempo polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PO$ = classe di problemi di ottimizzazione per cui il problema di decisione sottostante appartiene a $P$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$NPO$ = classe di problemi di ottimizzazione per cui il problema di decisione sottostante appartiene ad $NP$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$PO \\subseteq NPO$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **NP-hard**: un problema di ottimizzazione in $NPO$ è NP-hard se il suo problema di decisione sottostante è NP-completo\n",
    "- **TEOREMA**: Se $P \\neq NP$, un problema di ottimizzazione NP-hard NON può essere risolto in tempo polinomiale.\n",
    "- **TEOREMA**: Se $P = NP$, $PO = NPO$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- design di algoritmi che ritornano soluzioni **vicine** a quelle ottime."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ALGORITMI DI APPROSSIMAZIONE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vogliamo risolvere un problema **NP-hard**, cosa facciamo ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacrifichiamo una delle feature desiderate:\n",
    "- risolvi istanze arbitrarie del problema\n",
    "- risolvi il problema all'ottimo* (sacrifichiamo questa feature: design di algoritmi di approssimazione)\n",
    "- risolvi il problema in tempo polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- creazione di algoritmi capaci di restiuire soluzioni **vicine** a quelle ottime, cioè buone **approssimazioni**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dato un problema di minimizzazione e un numero $r \\geq 1$, un algoritmo $A$ è un algoritmo $r$-approssimante per il problema $\\pi$ se per ogni input $x \\in I$, l'algoritmo ritorna sempre una soluzione $r$-approssimata, cioè una soluzione feasible $y \\in S(x)$ tale che: $${m(x,y) \\over m^*(x)} \\leq r$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- dato un problema di massimizzazione e un numero $r \\leq 1$, un algoritmo $A$ è un algoritmo $r$-approssimante per il problema $\\pi$ se per ogni input $x \\in I$, l'algoritmo ritorna sempre una soluzione $r$-approssimata, cioè una soluzione feasible $y \\in S(x)$ tale che: $${m(x,y) \\over m^*(x)} \\geq r$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- come determiniamo il fattore di approssimazione $r$ se non sappiamo valore $m^*$ di una soluzione ottima?\n",
    "\t- per problemi di minimizzazione compariamo il valore della soluzione ritornata $m(x,y)$ con lower bound $l(x)$ di $m^*(x)$\n",
    "\t- per problemi di massimizzazione compariamo il valore della soluzione ritornata $m(x,y)$ con upper bound $u(x)$ di $m^*(x)$\n",
    "\n",
    "- se il rapporto è $\\leq r$ per MIN o $\\geq r$ per MAX, allora l'algoritmo è $r$-approssimante:\n",
    "    - se ${m(x,y) \\over l(x)} \\leq r$ allora ${m(x,y) \\over m*(x)} \\leq {m(x,y) \\over l(x)} \\leq r$ \t(per MIN)\n",
    "    - se ${m(x,y) \\over u(x)} \\geq r$ allora ${m(x,y) \\over m*(x)} \\geq {m(x,y) \\over u(x)} \\geq r$ \t(per MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo di approssimazione per Min vertex cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min vertex cover:\n",
    "**INPUT**: grafo $G=(V,E)$\n",
    "\n",
    "**SOLUZIONE**: $U \\subseteq V$, tale che: $u \\in U$ oppure $v \\in U$, per ogni $\\{u,v\\} \\in E$\n",
    "\n",
    "**MISURA**: $|U|$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo approx-cover:\n",
    "`BEGIN\n",
    "\n",
    "\tM = Ø  \t// archi scelti dall'algoritmo\n",
    "\tU = Ø \t// nodi scelti nel cover\n",
    "\tREPEAT\n",
    "\t\t- seleziona arco {u,v} che appartiene ad E\n",
    "\t\t- U = U u {u,v}\n",
    "\t\t- E = E \\ {e che appartiene ad E | e è incidente ad u OR è incidente a v}\n",
    "\t\t- M = M u {{u,v}}\n",
    "\tUNTIL(E=Ø)\n",
    "\tRETURN U\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: alla fine di esecuzione dell'algoritmo approx-cover, $M$ forma un matching (gli archi in $M$ non condividono nessun endpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- ogni volta che un arco $e$ viene messo in $M$, tutti gli archi incidenti sugli endpoints di $e$ sono rimossi da $E$. Perciò, nessun arco con estremo in comune con $e$ può essere scelto dall'algoritmo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: approx-cover è $2$-approssimante\n",
    "\n",
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- valore della soluzione ritornata dall'algoritmo è:\n",
    "     - $m = |U| = 2|M|$ \t// i nodi del matching M sono la soluzione U, per ogni arco ci sono 2 nodi ovviamente\n",
    "- sia $U^*$ il cover ottimo. Dato che gli archi in $M$ non condividono nessun endpoint ($M$ è un matching) e ciascuno di quegli archi deve avere un endpoint in $U^*$ (vertex cover), allora:\n",
    "\t- $m^* = |U^*| \\geq |M|$  // la grandezza di U* è almeno quella del matching M\n",
    "    \n",
    "perciò:\n",
    "\t$${m \\over m^*} \\leq {2|M| \\over |M|} = 2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECNICHE ALGORITMICHE: GREEDY"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- soluzione determinata in steps\n",
    "- ad ogni step, effettua la scelta che sembra essere la migliore in quello step, senza pensare alle conseguenze negli step futuri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max 0-1 Knapsack:\n",
    "**INPUT**: insieme finito di oggetti $O$, profitto intero $p_i$ e volume intero $a_i$ per ogni $o_i \\in O$, intero positivo $b$\n",
    "\n",
    "**SOLUZIONE**: insieme di oggetti $Q \\subseteq O$ tale che:\n",
    "\t$$\\sum_{o_i \\in Q} a_i \\leq b$$\n",
    "    \n",
    "**MISURA**: profitto totale oggetti scelti (stanno in Q):\n",
    "\t$$\\sum_{o_i \\in Q} p_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- non possiamo considerare solo profitto, perchè oggetti potrebbero non entrare nello zaino\n",
    "- non possiamo considerare solo volume, perchè profitto oggetti potrebbe essere troppo basso"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- consideriamo oggetti in base a profitto per volume: rapporto $$p_i \\over a_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo greedy seleziona gli oggetti in ordine non-crescente secondi il rapporto $p_i \\over a_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo greedy-knapsack:\n",
    "`BEGIN\n",
    "\n",
    "\tQ = Ø\n",
    "\tv = 0 \t// v = volume corrente knapsack\n",
    "\t- ordina oggetti in ordine non-crescente secondo rapporto (p_i / a_i)\n",
    "\t- siano o_1,...,o_n gli oggetti listati in tale ordine\n",
    "\tFOR i = 1 to n DO:\n",
    "\t\tIF v + a_i <= b THEN:\n",
    "\t\t\tQ = Q u {o_i}\n",
    "\t\t\tv = v + a_i\n",
    "\tRETURN Q\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: per ogni $r < 1$, greedy-knapsack NON E' $r$-approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "- dato intero $k = {1 \\over r}$, consideriamo seguente istanza di max 0-1 knapsack:\n",
    "\t- per ogni $n \\geq 2$:\n",
    "\t\t- $b = k * n$\n",
    "\t\t- $n-1$ oggetti con profitto $p_i = 1$ e volume $a_i = 1$\n",
    "\t\t- $1$ oggetto con profitto $b-1$ e volume $b$\n",
    "\n",
    "- soluzione ritornata dall'algoritmo: l'insieme dei primi $n-1$ oggetti, $m = n-1$\n",
    "- soluzione ottima: l'insieme che contiene solamente l'ennesimo oggetto, $m^* = b-1 = k * n - 1$\n",
    "\n",
    "- quindi:\n",
    "\t$${m \\over m^*} = {(n-1) \\over (k * n -1)} \\leq {(n-1) \\over (n/r - 1)} <^* {(n-1) \\over (n/r - 1/r)} = {(n-1) \\over (1/r * (n-1))} = r$$\n",
    "    \n",
    "(\\*: ${1 \\over r} > 1$)\n",
    "\n",
    "(${m \\over m^*} < r$ per un problema di MAX (invece di $\\geq$))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- greedy-knapsack non ritorna una buona appossimazione perchè ignora l'oggetto con profitto massimo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo modified-greedy:\n",
    "`BEGIN\n",
    "\t- computa la soluzione greedy-knapsack Q_gr e sia m_gr la sua misura\n",
    "\t- consideriamo l'oggetto o_max che ha il massimo profitto p_max\n",
    "\t- IF (m_gr >= p_max) THEN RETURN Q_gr, ELSE RETURN Q = {o_max}\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA 1**: Sia $o_j$ il primo oggetto che l'algoritmo greedy-knapsack non mette nello knapsack e sia $m_j = \\sum_{i=1}^{j-1} p_i$, allora $m^* \\leq m_j + p_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "$m^* \\leq m_j + p_j$ viene direttamente osservando:\n",
    "- sia $v$ la somma dei volumi dei primi $j-1$ oggetti scelti\n",
    "- $m_j + p_j$ è il valore della soluzione ottima quando il volume dello knapsack è $v + a_j > b$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA 2**: $m^* \\leq m_{gr} + p_{max}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- diretta conseguenza del **LEMMA 1**, osservando che $m_j \\leq m_{gr}$ e $p_j \\leq p_{max}$.\n",
    "- quindi: $m^* \\leq m_j + p_j \\leq m_{gr} + p_{max}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo modified-greedy ritorna una soluzione di valore $max(m_{gr}, p_{max})$, che è almeno la metà di $m_{gr} + p_{max}$, cioè la metà di un upper bound di $m^*$ (**LEMMA 2**)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: modified-greedy è (${1 \\over 2}$)-approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "$$m_{Mo} \\geq max(m_{gr}, p_{max}) \\geq {(m_{gr} + p_{max}) \\over 2} \\geq {m^* \\over 2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min multiprocessor scheduling:\n",
    "**INPUT**: insieme $P$ di $n$ jobs, numeri di processori $h$, running time $t_j$ per ogni $p_j \\in P$\n",
    "\n",
    "**SOLUZIONE**: uno schedule per $P$, cioè una funzione $f:P \\rightarrow \\{1,\\dots,h\\}$\n",
    "\n",
    "**MISURA**: makespan o completion time di $f$, cioe:\n",
    "\t$$\\max_{i \\in [1,\\dots,h]} \\sum_{p_j \\in P | f(p_j) = i} t_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo greedy di Graham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ad ogni passo, assegna un job al processore meno carico"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$T_i(j)$ = completion time (somma dei running times dei jobs assegnati) del processore $i$ alla fine dell'istante $j$ (cioè, una volta schedulati i primi $j$ jobs (in qualsiasi ordine))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo greedy di Graham:\n",
    "`BEGIN\n",
    "\t- siano p_1,...,p_n i jobs listati in qualsiasi ordine\n",
    "\tFOR j = 1 to n DO:\n",
    "\t\t- assegna p_j al processore i con minimo T_i(j - 1) \t// cioè f(p_j) = i\n",
    "\tRETURN schedule f\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- se i jobs sono schedulati in ordine di arrivo: online $\\rightarrow$ algoritmo assegna ogni job senza conoscere job futuri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**FATTO**: dato $s \\geq 0$ e $h$ numeri $a_1,\\dots,a_h$ tale che $a_1 + \\dots + a_h = s$, esiste $j$ con $1 \\leq j \\leq h$, tale che $a_j \\geq {s \\over h}$ (altrimenti $a_1 + a_2 + \\dots + a_h < h \\cdot {s \\over h} = s$, contraddizione) e analogamente esiste $j'$ con $1 \\leq j' \\leq h$, tale che $a_{j^{'}} \\leq {s \\over h}$: un numero è al più la media ed uno è almeno la media"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quindi: $min_j a_j \\leq {s \\over h}$ e $max_j a_j \\geq {s \\over h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: L'algoritmo di Graham è ($2 - {1 \\over h}$)-approssimante, con $h$ numero di processori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- sia $T$, la somma di tutti i running time dei jobs, cioè $\\sum_{j=1}^{n} t_j$.\n",
    "- sia $T^*_1,\\dots,T^*_h$ i completion times degli h processori in una soluzione ottima.\n",
    "- dato che $T^*_1 + \\dots + T^*_h = T$, dal precedente **FATTO** sappiamo che $T^*_j \\geq T/h$. Quindi $m^* \\geq T^*_j \\geq T/h$\n",
    "- sia $k$ un processore con massimo completion time nello schedule $f$ ritornato dall'algoritmo, cioè massimo $T_k(n)$\n",
    "- sia $p_l$ l'ultimo job assegnato al processore $k$.\n",
    "- dato che, per la scelta greedy, il processo $p_l$ è stato assegnato al processore meno carico all'inizio dello step l, dal precedente **FATTO** abbiamo che:\n",
    "\t$$T_k(l - 1) \\leq {\\sum_{j < l} t_j \\over h} \\leq {T - t_l \\over h}$$\n",
    "\n",
    "- dato che la somma dei running times di tutti i jobs assegnati prima di $p_l$ è al più $T - t_l$:\n",
    "\n",
    "$$m = T_k(n) \\leq T_k(l - 1) + t_l \\leq {T - t_l \\over h} + t_l \\leq {T \\over h} + ({(h - 1) \\over h}) * t_l \\leq^*  m^* + ({(h - 1) \\over h}) * m^* = (2 - {1 \\over h}) * m^*$$\n",
    "\n",
    "(\\*: perchè ${T \\over h} \\leq m^*$ e $t_l \\leq m^*$)\n",
    "\n",
    "Quindi:\n",
    "\n",
    "$${m \\over m^*} \\leq {(2 - {1 \\over h}) * m^* \\over m^*} = 2 - {1 \\over h}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quando $h$ cresce, il rapporto tende a $2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: L'algoritmo di Graham non è $r$-approssimante per $r < 2 - {1 \\over h}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- consideriamo seguente istanza:\n",
    "\t- $h * (h - 1)$ jobs con running time $1$\n",
    "\t- $1$ job con running time $h$\n",
    "- L'algoritmo di Graham assegna i jobs. Avremmo che $m = h + h - 1 = 2h - 1$\n",
    "- La soluzione ottima è invece assegnare il job più grande ad $1$ processore ed assegnare i restanti jobs ai restanti processori.\n",
    "La misura della soluzione ottima è quindi $m^* = h$\n",
    "- Quindi:\n",
    "\t$${m \\over m^*} = {2h-1 \\over h} = 2 - {1 \\over h}$$ \n",
    "    \n",
    "(non è $\\leq$ come dovrebbe essere un'approssimazione per un problema di MIN) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- possiamo migliorare il rapporto di approssimazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nella dimostrazione abbiamo fatto uso dei seguenti **lower bounds** ad $m^*$:\n",
    "    - $m^* \\geq T/h$: in ogni soluzione almeno un processore deve avere completion time $T/h$\n",
    "    - $m^* \\geq t_j$, per ogni job $p_j$: in ogni soluzione uno dei processori deve runnare $p_j$ (nel caso in cui prendiamo in considerazione l'ultimo job, $m^* \\geq p_l$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Quindi:\n",
    "    - $T/h \\leq m^*$\n",
    "    - $t_l \\leq m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- miglioramento:\n",
    "    - diminuiamo $t_l$ quanto possibile e troviamo un miglior rapporto\n",
    "- modificando l'algoritmo e/o migliorando l'analisi progressivamente possiamo limitare superiormente $t_l$ con $m^* \\over 2$ ($3\\over2$ - approssimato), $m^* \\over 3$ ($4 \\over 3$ - approssimato) e $\\epsilon m^*$ (($1+\\epsilon$) - approssimato, PTAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- primo miglioramento:\n",
    "    - assegnamo i jobs dai più grandi ai più piccoli:\n",
    "        - evitiamo così il caso peggiore dell'algoritmo di Graham (il job più lungo arriva per ultimo sbilanciando i carichi dei processori)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo ordered-greedy:\n",
    "`BEGIN\n",
    "    - sia p_1,...,p_n i jobs listati in ordine non-crescente rispetto ai loro running times (t_1 >= t_2 >= ... >= t_n)\n",
    "    FOR j=1 TO n DO:\n",
    "        - Assegna p_j al processore i con minimo T_i(j - 1)  // cioè: f(p_j)=i\n",
    "    RETURN schedule f\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- questo algoritmo porterà ad un rapporto di approssimazione di circa $3 \\over 2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: Se $n > h$, allora $t_{h+1} \\leq {m^* \\over 2 }$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- dall'ordinamento dei jobs, i primi $h+1$ hanno running time $\\geq t_{h+1}$\n",
    "- quindi $m^* \\geq 2t_{h+1}$, dato che in ogni schedule almeno uno degli $h$ processori deve ricevere almeno 2 dei primi $h+1$ jobs\n",
    "\n",
    "(quindi: $t_{h+1} \\leq {m^* \\over 2}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: ordered-greedy è (${3 \\over 2} - {1 \\over 2h}$) - approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- sia $k$ uno dei processori più carichi (alla fine).\n",
    "- se $k$ ha 1 solo job, allora la soluzione ritornata è quella ottima\n",
    "- altrimenti: consideriamo l'ultimo job $p_l$ assegnato a $k$.\n",
    "- $l \\geq h+1$ e quindi $t_l \\leq t_{h+1} \\leq {m^* \\over 2}$ (dall'ordinamento dei jobs e dal **LEMMA** precedente)\n",
    "- e quindi:\n",
    "$$ m \\leq {T \\over h} + { h - 1 \\over h }*t_l \\leq m^* + {h - 1 \\over h} * {m^* \\over 2} = ({3 \\over 2} - {1 \\over 2h})*m^*$$\n",
    "\n",
    "(con ${T \\over h} \\leq m^*$ e $t_l \\leq {m^* \\over 2}$ (bound migliorato))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max cut:\n",
    "**INPUT**: Grafo $G=(V,E)$\n",
    "\n",
    "**SOLUZIONE**: partizione di $V$ in 2 sottoinsiemi $V_1$ e $V_2$, tale che: $V_1 \\cup V_2 = V$ e $V_1 \\cap V_2 = \\emptyset$\n",
    "\n",
    "**MISURA**: cardinalità del cut, cioè il numero di archi con un endpoint in $V_1$ ed un endpoint in $V_2$:\n",
    "$$ | \\{ \\{u,v\\} | u \\in V_1 \\land v \\in V_2 \\} | $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo greedy-max-cut:\n",
    "\n",
    "`BEGIN`\n",
    "\n",
    "    V_1 = V_2 = Ø\n",
    "    FOR i=1 to n DO:\n",
    "    \n",
    "        Δ_i = { {i,j} appartiene E | j < i }  //insieme degli archi {i, j<i}\n",
    "        U_i = { j | {i,j} appartiene Δ_i }    // insieme dei nodi adiacenti ad i\n",
    "        \n",
    "        δ_i = |Δ_i| = |U_i|\n",
    "        δ_1i = | V_1 intersezione U_i |\n",
    "        δ_2i = | V_2 intersezione U_i |    // δ_1i + δ_2i = δ_i\n",
    "        \n",
    "        IF δ_1i > δ_2i:\n",
    "            V_2 = V_2 unione {i}\n",
    "        ELSE\n",
    "            V_1 = V_1 unione {i}\n",
    "    \n",
    "    RETURN V1,V2\n",
    "`END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo ad ogni step inserisce un nuovo nodo in $V_1$ oppure in $V_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- greedy: \n",
    "    - allo step $i$, il nodo $i$ è inserito in modo da massimizzare il numero di nuovi archi nel cut:\n",
    "        - cioè inserisce in $V_1$ se il numero di archi che ha verso i nodi già inseriti in $V_2$ è $\\geq$ al numero di archi che ha verso i nodi già inseriti in $V_1$, altrimenti inserisce in $V_2$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: l'algoritmo greedy-max-cut è ($1 \\over 2$) - approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- dato che il cut può solo contenere un sottinsieme di tutti gli archi in $E$:\n",
    "$$m^* \\leq |E|$$\n",
    "- dimostreremo che la misura $m$ del cut ritornato dall'algoritmo è almeno la metà di tutti gli archi in $E$:\n",
    "$$m \\geq {|E| \\over 2}$$\n",
    "- questo dimostrerebbe l'affermazione, dato che:\n",
    "$${m \\over m^*} \\geq { {|E| \\over 2} \\over |E| } = {1 \\over 2}$$\n",
    "\n",
    "- dato che gli insiemi $\\Delta_i$ determinati dall'algoritmo formano una partizione di $E$ e $\\delta_i = |\\Delta_i|$, abbiamo che:\n",
    "$$ \\sum_{i=1}^{n} \\delta_i = \\sum_{i=1}^{n} |\\Delta_i| = |E| $$\n",
    "\n",
    "- inoltre, il numero di archi aggiunti al cut nello step $i$ è: \n",
    "$$max(\\delta_{1i}, \\delta_{2i}) \\geq {(\\delta_{1i} + \\delta_{2i}) \\over 2 } = {\\delta_i \\over 2} $$\n",
    "\n",
    "- e quindi:\n",
    "\n",
    "$$ m = \\sum_{i=1}^{n} max(\\delta_{1i}, \\delta_{2i}) \\geq \\sum_{i=1}^{n} {\\delta_i \\over 2} = {|E| \\over 2} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusioni su tecnica greedy:\n",
    "- buone performance nella pratica\n",
    "- ma fare la scelta più conveniente ogni singolo step in generale non permette loro di trovare la soluzione ottima"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECNICHE ALGORITMICHE: LOCAL SEARCH"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- definiamo per ogni soluzione feasible $y$ un sottoinsieme di soluzioni feasible vicine chiamato neighborhood($y$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- iniziando dalla soluzione iniziale, progressivamente switchamo ad una soluzione migliore nel neighborhood corrente, fino a quando è possibile"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Schema di un algoritmo local search:\n",
    "\n",
    "`BEGIN\n",
    "    - fissiamo una soluzione iniziale y feasible per input x\n",
    "    WHILE (esiste y' appartiene neighborhood(y) migliore di y)\n",
    "        - sia y = y'\n",
    "    RETURN y\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- per definire un algoritmo di local search per un dato problema, dobbiamo definire:\n",
    "    - la soluzione iniziale\n",
    "    - il neighborhood delle soluzioni feasible"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità:\n",
    "\n",
    "- per avere complessità polinomiale nel tempo:\n",
    "    - la soluzione iniziale deve essere determinata in tempo polinomiale\n",
    "    - il test del WHILE e la determinazione di una soluzione migliore devono essere fatti in tempo polinomiale\n",
    "    - il numero delle iterazioni WHILE deve essere polinomiale (ATTENZIONE: il neighborhood può avere taglia esponenziale rispetto alla grandezza dell'input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approssimazione:\n",
    "- la soluzione ritornata $y$ non ha soluzioni migliori nel suo neighborhood, cioè è un ottimo locale\n",
    "- per limitare il rapporto di approssimazione bisogna limitare il rapporto tra il valore di un qualsiasi ottimo locale con quello della misura di un ottimo globale (soluzione ottima)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Utilizziamo local search per risolvere max cut"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo local search per max cut:\n",
    "1. Soluzione iniziale: $V_1 = V$ e $V_2 = \\emptyset$\n",
    "2. Neighborhood: dati $V = \\{v_i, \\dots , v_n\\}, V_1, V_2$, le soluzioni neighbor di $(V_1, V_2)$ sono tutte le coppie $(V_{1i}, V_{2i})$ con $1 \\leq i \\leq n$ che possono essere ottenute muovendo un nodo $v_i$ da $V_1$ a $V_2$ o viceversa che sono tale che:\n",
    "\n",
    "- IF $v_i \\in V_1$:\n",
    "    - $V_{1i} = V_1 \\backslash \\{v_i\\}$\n",
    "    - $V_{2i} = V_2 \\cup \\{v_i\\}$\n",
    "- ELSE IF $v_i \\in V_2$\n",
    "    - $V_{1i} = V_1 \\cup \\{v_i\\}$\n",
    "    - $V_{2i} = V_2 \\backslash \\{v_i\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complessità:\n",
    "- soluzione iniziale ottenuta in tempo polinomiale\n",
    "- test guardia WHILE e determinazione di una migliore soluzione neighbor entrambe in tempo polinomiale:\n",
    "    - per ciascuna delle $n$ soluzioni neighbor ($n$ iterazioni), controlliamo se la soluzione è migliore ($n^2$ iterazioni) -> $O(n^3)$\n",
    "- numero di iterazioni WHILE al più $|E| = O(n^2)$, dato che ogni iterazione migliora la soluzione corrente, cioè incrementa di almeno 1 il numero di archi nel cut e ci sono $|E|$ archi nel taglio\n",
    "\n",
    "- quindi l'algoritmo ha complessità temporale: $O(n^3 \\cdot n^2) = O(n^5)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Approssimazione:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- proprietà utile per dimostrare il rapporto di approssimazione dell'algoritmo:\n",
    "\n",
    "**FATTO**: Dato un grafo $G=(V,E)$, sia $\\delta_i$ il grado di un generico nodo $v_i \\in V$. Allora:\n",
    "$$ \\sum_{i=1}^{n} \\delta_i = 2|E| $$\n",
    "\n",
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- vero, dato che ciascun arco viene contato 2 volte nella somma."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: l'algoritmo local search è ($1 \\over 2$) - approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- Dimostreremo che ciascun ottimo locale $(V_1, V_2)$ ha misura $m \\geq {|E| \\over 2}$\n",
    "- questo implica che ${m \\over m^*} \\geq { { |E| \\over 2 } \\over |E| } = {1 \\over 2}$, dato che $m^* \\leq |E|$\n",
    "\n",
    "- dato un ottimo locale $(V_1, V_2)$, denotiamo con $h$ il numero di archi interni, cioè con entrambi gli endpoints in $V_1$ oppure in $V_2$. Abbiamo che $m + h = |E|$\n",
    "- per ogni nodo $v_i \\in V$, definiamo i gradi interni ed esterni del nodo come segue:\n",
    "    - $\\delta_i^{int}$ = numero di archi che $v_i$ ha verso i nodi nella sua partizione.\n",
    "    - $\\delta_i^{ext}$ = numero di archi che $v_i$ ha verso i nodi nell'altra partizione.\n",
    "- dato che la soluzione neighbor $(V_{1i}, V_{2i})$ ha misura non maggiore di quella di $(V_1, V_2)$ (l'ottimo locale), abbiamo quindi: $m - \\delta_i^{ext} + \\delta_i^{int} \\leq m$ e quindi $\\delta_i^{int} - \\delta_i^{ext} \\leq 0$\n",
    "- sommando su tutti i nodi $v_i$:\n",
    "$$\\sum_{v_i \\in V} \\delta_i^{int} - \\sum_{v_i \\in V} \\delta_i^{ext} = \\sum_{v_i \\in V} (\\delta_i^{int} - \\delta_i^{ext}) \\leq 0$$\n",
    "- dal precedente **FATTO** abbiamo che:\n",
    "    - $\\sum_{v_i \\in V} \\delta_i^{int} = 2h$\n",
    "    - $\\sum_{v_i \\in V} \\delta_i^{ext} = 2m$\n",
    "    \n",
    "- quindi:\n",
    "$$ 0 \\geq \\sum_{v_i \\in V} \\delta_i^{int} - \\sum_{v_i \\in V} \\delta_i^{ext} = 2h - 2m $$\n",
    "- cioè:\n",
    "$$ m \\geq h $$\n",
    "- aggiungendo m ad entrambi i lati e dividendo per 2:\n",
    "$$ m + m \\geq m + h \\Rightarrow 2m \\geq m + h \\Rightarrow m \\geq {m+h \\over 2} \\geq { |E| \\over 2 }$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### conclusioni su local search:\n",
    "- come gli algoritmo greedy, gli algoritmo local search hanno buone performance nella pratica, ma di solito non hanno prestazioni garantite in termini di tempo o approssimazione."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECNICHE ALGORITMICHE: PROGRAMMAZIONE LINEARE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- il problema è formulato come un Integer Linear Program (ILP)\n",
    "- ILP = linear program + vincoli di interezza\n",
    "- esiste un algoritmo di tempo polinomiale per risolvere problemi lineari ma risolvere un ILP è un problema NP-hard\n",
    "- la formulazione come ILP rende possibile utilizzare alcuni metodi che sono in grado di dare buoni algoritmi di approssimazione:\n",
    "    - Rounding\n",
    "    - Primale-Duale (soluzione ottima per primale è soluzione ottima per duale)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PROGRAMMAZIONE LINEARE: ROUNDING"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- il problema è formulato come un ILP\n",
    "- il rilassamento lineare (LP) è ottenuto dall'ILP rilassando i vincoli di interezza, cioè sostituendoli con adatti vincoli lineari\n",
    "- la soluzione ottenuta (ottima per LP) è arrotondata alla più vicina soluzione intera feasible per ILP\n",
    "- la misura $m$ della soluzione ottenuta è poi comparata con $m_{LP}^*$ (misura della soluzione ottima di LP), che è il lower bound (per MIN) o upper bound (per MAX) di $m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min weighted vertex cover:\n",
    "**INPUT**: grafo $G=(V,E)$, costo intero $c_j$ associato ad ogni $v_j \\in V$\n",
    "\n",
    "**SOLUZIONE**: $U \\subseteq V$, tale che $v_j \\in U$ oppure $v_k \\in U$ per ogni $\\{v_j, v_k\\} \\in E$\n",
    "\n",
    "**MISURA**: costo totale di $U$, cioè:\n",
    "$$\\sum_{v_j \\in U} c_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILP:\n",
    "$$min \\sum_{v_j \\in V} c_j \\cdot x_j$$ s.t.\n",
    "$$x_j + x_k \\geq 1$$ per ogni $\\{v_j, v_k\\} \\in E$ \n",
    "$$x_j \\in \\{0,1\\}$$ per ogni $v_j \\in V$, per ogni $j$, con $1 \\leq j \\leq n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LP (rilassamento lineare):\n",
    "$$min \\sum_{v_j \\in V} c_j \\cdot x_j$$ s.t.\n",
    "$$x_j + x_k \\geq 1$$ per ogni $\\{v_j, v_k\\} \\in E$ \n",
    "$$x_j \\geq 0$$ per ogni $v_j \\in V$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo round-vertex-cover:\n",
    "`BEGIN\n",
    "    - determina ILP associato all'istanza di input\n",
    "    - risolvi il rilassamento lineare LP e sia <x*_1,...,x*_n> la soluzione ottima del LP\n",
    "    - per ogni v_j, sia x_j = 1, IF x*_j >= 1/2 e\n",
    "                  sia x_j = 0, IF x*_j < 1/2\n",
    "    - ritorna il cover U associato a <x_1,...,x_n> cioè tale che U = {v_j appartiene V | x_j = 1}\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: round-vertex-cover è un algoritmo $2$-approssimante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- bisogna mostrare che:\n",
    "    1. $x_1,\\cdots, x_n$ è feasible per ILP (soddisfa tutti i vincoli), cioè U è cover\n",
    "    2. ${m \\over m_{LP}^*} \\leq 2$ e quindi anche ${m \\over m^*} \\leq {m \\over m_{LP}^*} \\leq 2$\n",
    "\n",
    "- dimostramo ***1***:\n",
    "    - per la feasibility di $<x_1^*, \\cdots, x_n^*>$ per LP, per ogni arco $\\{v_j, v_k\\} \\in E$ abbiamo che $x_j^* + x_k^* \\geq 1$, cioè $x_j^* \\geq 0.5$ oppure $x_k^* \\geq 0.5$, così che $x_j = 1$ oppure $x_k = 1$, e quindi $x_j + x_k \\geq 1$ è soddisfatto nel ILP\n",
    "- dimostriamo ***2***:\n",
    "    - $$m = \\sum_{j=1}^{n} c_j \\cdot x_j \\leq^* \\sum_{j=1}^{n} c_j \\cdot 2 \\cdot x_j^* = 2 \\cdot \\sum_{j=1}^{n} c_j \\cdot x_j^* = 2 \\cdot m_{LP}^*$$\n",
    "    (\\*: per il rounding: $x_j \\leq 2 \\cdot x_j^*$)\n",
    "    - cioè: $${m \\over m^*} \\leq {m \\over m_{LP}^*} \\leq 2$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min weighted set cover:\n",
    "**INPUT**: universo $U = \\{o_1,\\cdots,o_n\\}$ di $n$ oggetti, famiglia $\\hat{S}=\\{S_1,\\cdots,S_h\\}$ di $h$ sottoinsiemi di $U$, costo intero $c_j$ associato ad ogni $S_j \\in \\hat{S}$ \n",
    "\n",
    "**SOLUZIONE**: cover di $U$, cioè sottofamiglia $\\hat{C} \\subseteq \\hat{S}$ tale che:\n",
    "$$ \\bigcup_{S_j \\in \\hat{C}} S_j = U $$\n",
    "\n",
    "**MISURA**: costo totale cover, cioè:\n",
    "$$ \\sum_{S_j \\in \\hat{C}} c_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min wighted set cover**: identificare la più piccola sottocollezione di $S$, la cui unione è uguale all'universo $U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$ = frequenza massima di un oggetto nei sottoinsiemi di $\\hat{S}$, ogni oggetto occorre in al più $f$ sottinsiemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ILP:\n",
    "$$min \\sum_{j=1}^{h} c_j \\cdot x_j$$ s.t.\n",
    "$$\\sum_{S_j | o_i \\in S_j} x_j \\geq 1$$ per ogni $o_i \\in U$ \n",
    "$$x_j \\in \\{0,1\\}$$ per ogni $S_j \\in \\hat{S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LP:\n",
    "$$min \\sum_{j=1}^{h} c_j \\cdot x_j$$ s.t.\n",
    "$$\\sum_{S_j | o_i \\in S_j} x_j \\geq 1$$ per ogni $o_i \\in U$ \n",
    "$$x_j \\geq 0$$ per ogni $S_j \\in \\hat{S}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo round-set-cover:\n",
    "`BEGIN\n",
    "    - determina ILP associato all'istanza di input\n",
    "    - risolvi il rilassamento lineare LP dell'ILP e sia <x*_1,...,x*_n> la soluzione ottima del LP\n",
    "    - per ogni S_j, sia x_j = 1 IF x*_j >= 1/f e\n",
    "                    sia x_j = 0 IF x*_j < 1/f\n",
    "    - ritorna il cover risultante, cioè C^ = { S_j appartiene S^ | x_j = 1 }\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: round-set-cover è $f$-approssimante (per $f \\geq 1$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- bisogna dimostrare che:\n",
    "    1. $x_1,\\cdots,x_n$ è feasible per ILP\n",
    "    2. ${m \\over m_{LP}^*} \\leq f$ e quindi: ${m \\over m^*} \\leq {m \\over m_{LP}^*} \\leq f$\n",
    "- dimostriamo ***1***:\n",
    "    - dalla feasibility di $<x_1^*,\\cdots,x_n^*>$ per LP, per ogni $o_i \\in U$ abbiamo che $\\sum_{S_j | o_i \\in S_j} x_j^* \\geq 1$, dato che questa sommatoria ha al più $f$ termini, deve esistere $S_j$ che contiene $o_i$ tale che $x_j^* \\geq {1 \\over f}$ cioè, tale che, $x_j = 1$, e quindi: $\\sum_{S_j | o_i \\in S_j} x_j \\geq 1$\n",
    "- dimostriamo ***2***:\n",
    "    - $$m = \\sum_{j=1}^{h} c_j \\cdot x_j \\leq^* \\sum_{j=1}^{h} c_j \\cdot f \\cdot x_j^* = f \\cdot \\sum_{j=1}^{h} c_j \\cdot x_j^* = f \\cdot m_{LP}^*$$\n",
    "    (\\*: dal rounding $x_j \\leq f \\cdot x_j^*$)\n",
    "- cioè:\n",
    "$${m \\over m^*} \\leq {m \\over m_{LP}^*} \\leq f$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TECNICHE ALGORITMICHE: PROGRAMMAZIONE DINAMICA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **come paradigma divide et impera**: dividere un problema in piccoli sottoproblemi, risolvere ricorsivamente ciascun sottoproblema e combinare le soluzioni dei sottoproblemi per formare la soluzione al problema originale\n",
    "- **differentemente dal divide et impera**: i sottoproblemi non sono indipendenti, ma sovrapposti (durante le decomposizioni, gli stessi sottoproblemi occorrono frequentemente)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **ciascun sottoproblema è risolto solo 1 volta**, riducendo la complessità temporale\n",
    "- **differentemente dal divide et impera** generalemente si ha un approccio bottom-up invece di top-down, cioè, partendo dai sottoproblemi più piccoli risolviamo progressivamente quelli più grandi, fino al problema iniziale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- il **paradigma divide et impera è basato sulla decomposizione dei problemi in sottoproblemi più piccoli**:\n",
    "    - ricorsivamente risolvi i sottoproblemi\n",
    "    - combina le soluzioni dei sottoproblemi per determinare la soluzione al problema iniziale\n",
    "- se un problema di grandezza $n$ è decomposto in $k$ sottoproblemi, ognuno di grandezza $< n$, allora la complessità temporale può essere espressa dalla ricorrenza:\n",
    "$$T(n) = T(n_1) + \\cdots + T(n_k) + C(n)$$\n",
    "dove $C(n)$ è il tempo per combinare le k sottosoluzioni"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la ricorrenza può essere risolta con il Teorema Master"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- esempio dell'applicazione del divide et impera sono i numeri di Fibonacci:\n",
    "    - caso base ($n \\leq 2$): $F(1) = F(2) = 1$\n",
    "    - caso induttivo ($n > 2$): $F(n) = F(n-1) + F(n-2)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Fibonacci(n):\n",
    "`BEGIN\n",
    "    IF (n = 1) OR (n = 2):\n",
    "        RETURN 1\n",
    "    ELSE:\n",
    "        RETURN Fibonacci(n-1) + Fibonacci(n-2)\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Complessità temporale:\n",
    "    - $T(n) = T(n-1) + T(n-2) + \\Theta(1)$, cioè: $T(n) = O(2^n)$\n",
    "- inefficiente: stessi problemi risolti di nuovo varie volte"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- programmazione dinamica: salva la soluzione ad ogni sottoproblema in una tabella, quindi evitiamo di risolverli di nuovo\n",
    "- F array globale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Fibonacci2(n):\n",
    "`BEGIN\n",
    "    IF (n = 1) OR (n = 2):\n",
    "        F[n] = 1, RETURN F[n]\n",
    "    ELSE:\n",
    "        IF F[n] è stato assegnato:\n",
    "            RETURN F[n]\n",
    "        ELSE:\n",
    "            F[n] = Fibonacci2(n-1) + Fibonacci2(n-2)\n",
    "            RETURN F[n]\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Fibonacci3(n):\n",
    "`BEGIN\n",
    "    F[1] = 1\n",
    "    F[2] = 1\n",
    "    FOR i=3 TO n DO:\n",
    "        F[i] = F[i-1] + F[i-2]\n",
    "    RETURN F[n]\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sintetizzando"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in programmazione dinamica:\n",
    "    - problema iniziale ricorsivamente decomposto in sottoproblemi\n",
    "    - stessi sottoproblemi occorrono molte volte ma sono risolti 1 sola volta\n",
    "    - soluzione di un sottoproblema può essere ottenuta combinando quelle dei sottoproblemi più piccoli\n",
    "    \n",
    "    - 2 possibili implementazioni:\n",
    "        - top-down con table annotation (memoization)\n",
    "        - bottom-up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- top-down:\n",
    "    - sfrutta table annotation\n",
    "    - **pros**: risolve solo i sottoproblemi strettamente necessari\n",
    "    - **cons**: overhead catena chiamate ricorsive\n",
    "- bottom-up:\n",
    "    - scelta tipica in programmazione dinamica\n",
    "    - **pros**: elimina peso ricorsione (in generale questo lo rende più performante)\n",
    "    - **cons**: risolve anche sottoproblemi non necessari"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- divide et impera:\n",
    "    - tecnica ricorsiva\n",
    "    - approccio **top-down**\n",
    "    - conveniente se sottoproblemi sono **indipendenti** (cioè, differenti), altrimenti stessi problemi risolti più volte\n",
    "- programmazione dinamica:\n",
    "    - tecnica iterativa\n",
    "    - approccio **bottom-up**\n",
    "    - conveniente se sottoproblemi si **sovrappongono** (cioè, coincidono)\n",
    "    - ciascun sottoproblema risolto solo 1 volta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design di algoritmi di programmazione dinamica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. fornisci decomposizione ricorsiva dei sottoproblemi\n",
    "2. computa le sottosoluzioni **bottom-up** (partendo dai sottoproblemi più piccoli):\n",
    "    - usa una tabella per salvare risultati dei sottoproblemi\n",
    "    - evita computazione delle stesse soluzioni sfruttando tabella\n",
    "3. combina la soluzioni dei sottoproblemi già risolti per costruire soluzioni per sottoproblemi sempre più grandi, fino a risolvere il problema originale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità degli algoritmi di programmazione dinamica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- (**grandezza tabella**) x (**tempo combinazione sottosoluzioni** = sempre polinomiale) \n",
    "- quindi: **polinomiale**, se la tabella ha grandezza **polinomiale** (solo se ci sono un numero polinomiale di sottoproblemi differenti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max 0-1 Knapsack (recall):\n",
    "**INPUT**: insieme finito di oggetti $O$, profitto intero $p_i$ e peso intero $w_i$ per ogni $o_i \\in O$, intero positivo $b$\n",
    "\n",
    "**SOLUZIONE**: insieme di oggetti $Q \\subseteq O$ tale che:\n",
    "\t$$\\sum_{o_i \\in Q} w_i \\leq b$$\n",
    "    \n",
    "**MISURA**: profitto totale oggetti scelti (stanno in Q):\n",
    "\t$$\\sum_{o_i \\in Q} p_i$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmo brute force"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- semplice algoritmo:\n",
    "    - enumera tutti i possibili $2^n$ sottoinsiemi di $n$ elementi\n",
    "    - scegli la migliore combinazione (miglior profitto con vincolo di peso soddisfatto)\n",
    "- algoritmo di programmazione dinamica generalmente esegue molto meglio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Design dell'algoritmo (di programmazione dinamica)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(i,w)$ = sottinsieme di massimo profitto di oggetti $1,\\cdots,i$ con limite ($\\leq$) di peso $w$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(n,b)$ = soluzione ottima per problema iniziale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ci sono 2 alternative per OPT (mutualmente esclusive):\n",
    "    - OPT non seleziona oggetto $i$:\n",
    "        - seleziona meglio di $\\{1,\\cdots,i-1\\}$ usando limite peso $w$\n",
    "    - OPT seleziona oggetto $i$:\n",
    "        - seleziona meglio di $\\{1,\\cdots,i-1\\}$ usando limite peso $w - w_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(k,w)$ = soluzione ottima per elementi $\\{o_1,\\cdots,o_k\\}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la soluzione ottima $OPT(k+1,w)$ potrebbe non corrispondere a $OPT(k,w)$, anche perchè $OPT(k+1,w)$ potrebbe non essere un superset di $OPT(k,w)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione ricorsiva per OPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(i,w)$:\n",
    "    - $\\emptyset$ IF $i = 0$\n",
    "    - $OPT(i-1,w)$ IF $w_i > w$\n",
    "    - il meglio tra $OPT(i-1,w)$ e $OPT(i-1,w-w_i) \\cup \\{o_i\\}$ ELSE\n",
    "\n",
    "- misura $m(i,w)$ della soluzione ottima $OPT(i,w)$:\n",
    "    - $0$ IF $i = 0$\n",
    "    - $m(i-1,w)$ IF $w_i > w$\n",
    "    - $max\\{m(i-1,w),m(i-1,w-w_i)+p_i\\}$ ELSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $m^* = m(n,b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- come risultato, il miglior sottoinsieme di $k$ oggetti con vincolo su peso $w$ è:\n",
    "    - il miglior sottoinsieme di $k-1$ oggetti con peso totale $w$\n",
    "    - il miglior sottoinsieme di $k-1$ oggetti con peso totale $w-w_k$ ($w+$ contributo (cioè, peso) del $k$-esimo oggetto)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- quindi, per quanto riguarda la formula ricorsiva $OPT(i,w)$:\n",
    "    - il $k$-esimo oggetto non può essere parte della soluzione (dato che il suo peso è così grande che l'oggetto stesso non entra nello knapsack) [caso 2]\n",
    "    - [caso 3] altrimenti, scegliamo la migliore soluzione tra:\n",
    "        - la soluzione che include il nuovo oggetto\n",
    "        - la soluzione migliore che non include il nuovo oggetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo progr-dyn-knapsack:\n",
    "`BEGIN\n",
    "    FOR w=0 TO b DO:\n",
    "        M[0,w] = 0\n",
    "    FOR i=1 TO n DO:\n",
    "        FOR w=0 to b DO:\n",
    "            IF(w_i > w):\n",
    "                M[i,w] = M[i-1,w]\n",
    "            ELSE:\n",
    "                M[i,w] = max{ M[i-1,w], M[i-1,w-w_i] + p_i }\n",
    "    RETURN M[n,b]\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo nella pratica (esecuzione dell'esercizio di esempio):\n",
    "#### Inizializzazione (passo 0):\n",
    "`FOR w=0 TO W DO:\n",
    "    B[0,w] = 0\n",
    "FOR i=1 TO n DO:\n",
    "    B[i,0] = 0`\n",
    "\n",
    "#### Iterazione (ad ogni passo):\n",
    "`IF w_i <= w:\n",
    "    IF v_i + B[i-1,w-w_i] > B[i-1,w]:\n",
    "        B[i,w] = v_i + B[i-1,w-w_i]\n",
    "    ELSE:\n",
    "        B[i,w] = B[i-1,w]\n",
    "ELSE:\n",
    "    B[i,w] = B[i-1,w]`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo trova massimo profitto che può essere inserito nello knapsack, tale valore è memorizzato in $B[n,w]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- per scoprire gli oggetti che sono stati inseriti nella soluzione ottima (trovare gli elementi della soluzione ottima):\n",
    "\n",
    "`BEGIN\n",
    "    i = n\n",
    "    k = w\n",
    "    WHILE i,k > 0:\n",
    "        IF B[i,k] != B[i-1,k]:\n",
    "            - marca oggetto i come nello zaino\n",
    "            - k = k - w_i\n",
    "            - i = i - 1\n",
    "        ELSE:\n",
    "            - i = i - 1\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità temporale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: la complessità temporale di progr-dyn-knapsack è $O(n \\cdot b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- l'algoritmo impiega $O(1)$ per accedere a ciascuna entry della tabella\n",
    "- ci sono $O(n \\cdot b)$ entries nella tabella\n",
    "- dopo aver computato i valori, possiamo risalire per trovare la soluzione ottima:\n",
    "    - prendiamo item $o_i$ in $OPT(i,w)$ se $M[i-1,w] < M[i,w]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo è polinomiale ?\n",
    "- per essere polinomiale, la complessità deve essere polinomiale nel logaritmo di valori codificati nell'istanza di input (cioè rispetto a $log(b)$). Questa complessità è chiamata PSEUDO-POLINOMIALE, cioè polinomiale nella dimensione dell'input **e nei valori** dell'input (non solo nella dimensione dell'input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approccio duale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(i,p)$ = sottoinsieme di peso minimo degli oggetti $1,\\cdots,i$ con profitto almeno ($\\geq$) $p$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ci sono 2 alternative per $OPT(i,p)$:\n",
    "    - OPT non seleziona oggetto $i$:\n",
    "        - OPT seleziona il meglio di $\\{1,\\cdots,i-1\\}$ usando il limite sul profitto $p$\n",
    "    - OPT seleziona oggetto $i$:\n",
    "        - OPT seleziona il meglio di $\\{1,\\cdots,i-1\\}$ usando il limite sul profitto $p - p_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Definizione ricorsiva per OPT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $OPT(i,p)$:\n",
    "    - UNDEF IF $i = 0$\n",
    "    - migliore scelta tra $OPT(i-1,p)$ e $\\{o_i\\}$ IF $p_i \\geq p$\n",
    "    - migliore scelta tra $OPT(i-1,p)$ e $OPT(i-1,p-p_i) \\cup \\{o_i\\}$ ELSE (UNDEF se entrambi UNDEF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- in termini di peso $v(i,p)$ della soluzione ottima $OPT(i,p)$:\n",
    "    - $v(i,p)$:\n",
    "        - $\\infty$ IF $i = 0$\n",
    "        - $min\\{v(i-1,p),w_i\\}$ IF $p_i \\geq p$\n",
    "        - $min\\{v(i-1,p),v(i-1,p-p_i)+w_i\\}$ ELSE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo progr-dyn-knapsack-dual:\n",
    "`BEGIN\n",
    "    FOR p=1 TO P DO:\n",
    "        V[0,p] = infinity\n",
    "    FOR i=1 TO n DO:\n",
    "        FOR p=1 to P DO:\n",
    "            IF(p_i >= p):\n",
    "                V[i,p] = min{V[i-1,p],w_i}\n",
    "            ELSE:\n",
    "                V[i,p] = min{V[i-1,p], V[i-1,p-p_i]+w_i}\n",
    "    RETURN max p tale che V[n,p] <= b\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- come scegliere P ?\n",
    "- abbastanza grande da includere l'ottimo (cioè ogni upper bound ad $m^*$), cioè $P \\geq m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $P = n \\cdot p_{max} \\geq \\sum_{i=1}^{n} p_i \\geq m^*$ ($p_{max} = max \\{p_j\\}$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità temporale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: la complessità di progr-dyn-knapsack-dual è $O(n^2 \\cdot p_{max})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- l'algoritmo impiega $O(1)$ per accedere a ciascuna entry della tabella\n",
    "- ci sono $O(n \\cdot P) = O(n^2 \\cdot p_{max})$ entries nella tabella\n",
    "- dopo aver computato i valori, possiamo risalire per trovare la soluzione ottima: prendi item $o_i$ in $OPT(i,p)$ IF $V[i-1,p] > V[i,p]$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# POLYNOMIAL TIME APPROXIMATION SCHEMES (PTAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un algoritmo $A$ per un problema di ottimizzazione $\\pi \\in NPO$ è un PTAS per $\\pi$ se, data un'istanza di input $x \\in I$ e un numero razionale $\\epsilon > 0$, ritorna una soluzione $(1+\\epsilon)$-approssimata (Per MIN) o una soluzione $(1-\\epsilon)$-approssimata (per MAX) in tempo polinomiale rispetto alla taglia dell'istanza $x$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la complessità può essere esponenziale in $1 \\over \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- la complessità di un PTAS può crescere drasticamente quando $\\epsilon$ descresce\n",
    "- es. $O(n^{1 \\over \\epsilon})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- per ogni valore fissato di $\\epsilon$, un PTAS corrisponde ad un algoritmo di tempo polinomiale $(1+\\epsilon)$-approssimato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min multiprocessor scheduling: (recall)\n",
    "**INPUT**: insieme $P$ di $n$ jobs, numeri di processori $h$, running time $t_j$ per ogni $p_j \\in P$\n",
    "\n",
    "**SOLUZIONE**: uno schedule per $P$, cioè una funzione $f:P \\rightarrow \\{1,\\dots,h\\}$\n",
    "\n",
    "**MISURA**: makespan o completion time di $f$, cioe:\n",
    "\t$$\\max_{i \\in [1,\\dots,h]} \\sum_{p_j \\in P | f(p_j) = i} t_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Recap dell'algoritmo Greedy di Graham"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **scelta greedy**: ad ogni step, assegna un job ad uno dei processori meno carichi correntemente"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- abbiamo fatto uso dei seguenti **lower bounds** ad $m^*$:\n",
    "    - $m^* \\geq {T \\over h}$: in ogni soluzione almeno $1$ processore deve avere completion time $T \\over h$\n",
    "    - $m^* \\geq t_j$ per ogni job $p_j$: in ogni soluzione $1$ dei processori deve runnare $p_j$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- per limitare superiormente **(upper bound)** il valore della soluzione ritornata, abbiamo utilizzato $p_l$, cioè l'ultimo job assegnato a $k$, uno dei processori più carichi, e abbiamo derivato le disuguaglianze"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- abbiamo progressivamente migliorato la complessità:\n",
    "    - decrementando $t_l$ fino a quando è possibile troviamo un rapporto migliore sfruttando le disuguaglianze\n",
    "    - modificando l'algoritmo e migliorando l'analisi abbiamo limitato superiormente **(upper bound)** $t_l$ con ${m^* \\over 2}$ ($3 \\over 2$-approssimante)\n",
    "    - ora, settiamo $t_l$ arbitrariamente piccolo, cioè $\\epsilon \\cdot m^*$, per produrre un algoritmo $(1+\\epsilon)$-approssimante, cioè un PTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: se $t_1,\\cdots,t_n$ sono ordinati in modo non-crescente, allora per ogni $i$, $1 \\leq i \\leq n$: $t_i \\leq {T \\over i}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- assumiamo per contraddizione che non sia così: $t_i > {T \\over i}$, allora:\n",
    "$$t_1 + \\cdots + t_i \\geq i \\cdot t_i > i \\cdot {T \\over i} = T$$\n",
    "una contraddizione, dato che $T = \\sum_{i=1}^{n} t_i$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PTAS: idea sottostante"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- computiamo la soluzione ottima per i primi $q$ jobs\n",
    "- completiamo assegnando in modo greedy i restanti jobs\n",
    "- se possiamo ottenere $t_l \\leq \\epsilon \\cdot m^*$, allora:\n",
    "$$m \\leq {T \\over h} + ({h-1 \\over h})*t_l < {T \\over h} + t_l \\leq m^* + \\epsilon \\cdot m^* = (1+\\epsilon) \\cdot m^*$$\n",
    "- usando il **LEMMA** precedente, è sufficiente impostare $q$ in modo giusto, dato che $l > q$\n",
    "- questo vale per: $q = \\lceil {h \\over \\epsilon} \\rceil$, infatti le disuguaglianze:\n",
    "$$t_l \\leq {T \\over l} \\leq {T \\over q+1} \\leq \\epsilon \\cdot {T \\over h} \\leq \\epsilon \\cdot m^*$$\n",
    "sono vere se $q \\geq {h \\over \\epsilon} - 1$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo PTAS-scheduling:\n",
    "`BEGIN\n",
    "    - ordina i jobs in modo non-crescente rispetto ai running time t_i e sia p_1,...,p_n la sequenza risultante (t_1>=...>=t_n)\n",
    "    - computa uno schedule ottimo f per i primi q = parte_intera_sup(h/epsilon) jobs\n",
    "    FOR j=q+1 TO n DO:\n",
    "        - assegna p_j al processore i con minimo T_i(j-1)  // cioè f(p_j) = i\n",
    "    RETURN schedule f\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: PTAS-scheduling ritorna sempre una soluzione $(1+\\epsilon)$-approssimata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- sia $t \\leq m^*$ il completion time per la soluzione ottima per i primi $q$ jobs\n",
    "- se $m \\leq t$: la fase greedy non ha incrementato il completion time, allora l'algoritmo ritorna una soluzione ottima\n",
    "- se $m > t$: denotiamo con $k$ il processore più carico alla fine dell'algoritmo e con $p_l$ l'ultimo job assegnato a $k$, allora:\n",
    "$$ m = T_k(n) = T_k(l-1) + t_l \\leq {T - t_l \\over h} + t_l = {T \\over h} + ({h-1 \\over h})*t_l < {T \\over h} + t_l \\leq m^* + \\epsilon \\cdot m^* = (1+\\epsilon) \\cdot m^*$$\n",
    "cioè:\n",
    "$$ {m \\over m^*} \\leq 1+\\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- l'algoritmo soddisfa il requisito di approssimazione di PTAS\n",
    "- ma vediamo se è un PTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ordinamento iniziale: $O(n \\cdot log(n))$\n",
    "- ricerca esaustiva di una soluzione ottima per i primi $q$ jobs: $O(h^{h \\over \\epsilon})$, dato che ci sono al più $h^q = h^{h \\over \\epsilon}$ soluzioni possibili ($h$ possibili scelte per ognuno dei $q$ jobs)\n",
    "- il FOR esegue al più $n$ iterazioni, ciascuna richiede $O(h)$: $O(n \\cdot h)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- complessità totale = $O(n \\cdot log(n) + h^{h \\over \\epsilon} + n \\cdot h)$\n",
    "- questa complessità è esponenziale in $h$, e quindi esponenziale nella dimensione dell'input\n",
    "- NON abbiamo un PTAS, a meno che non fissiamo che $h$ debba essere una costante\n",
    "- fissare $h$ costante è equivalente a dire che $h$ non dipende dall'input\n",
    "- praticamente corrisponde a considerare questo nuovo problema:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min $h$-processor scheduling:\n",
    "**INPUT**: insieme $P$ di $n$ jobs, running time $t_j$ per ogni $p_j \\in P$\n",
    "\n",
    "**SOLUZIONE**: uno schedule per $P$, cioè una funzione $f:P \\rightarrow \\{1,\\dots,h\\}$\n",
    "\n",
    "**MISURA**: makespan o completion time di $f$, cioe:\n",
    "\t$$\\max_{i \\in [1,\\dots,h]} \\sum_{p_j \\in P | f(p_j) = i} t_j$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: PTAS-scheduling è un PTAS per Min $h$-processor scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- l'algoritmo ha complessità $O(n \\cdot log(n) + h^{h \\over \\epsilon} + n \\cdot h)$\n",
    "- questa complessità è polinomiale nella grandezza di input ed esponenziale in $1 \\over \\epsilon$\n",
    "- l'approssimazione è $1+\\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Min $h$-processor scheduling con $h = 2$ è il Min partition problem, che ammette un PTAS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min partition:\n",
    "**INPUT**: insieme $X$ di oggetti, un peso intero positivo $a_i$ per ogni $o_i \\in X$\n",
    "\n",
    "**SOLUZIONE**: una partizione di $X$ in 2 sottoinsiemi $X_1$ e $X_2$ tali che $X_1 \\cap X_2 = \\emptyset$ e $X_1 \\cup X_2 = X$\n",
    "\n",
    "**MISURA**: $$max\\{ \\sum_{o_i \\in X_1} a_i , \\sum_{o_i \\in X_2} a_i \\}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- gli oggetti corrispondono ai jobs, i pesi ai running times, i 2 sottoinsiemi sono i 2 processori"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è possibile estendere il risultato per ottenere un PTAS per Min multiprocessor scheduling (cioè, con $h$ NON costante)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ricordiamo precedente dimostrazione di approssimazione per PTAS:\n",
    "    - denotiamo con $t$ il completion time dello schedule ottimo ottenuto per i primi $q$ jobs, ci sono 2 casi:\n",
    "        - $m \\leq t$: la soluzione ritornata dall'algoritmo non ha incrementato $t$ $\\rightarrow$ l'algoritmo ritorna la soluzione ottima\n",
    "        - $m > t$: c'è stato un incremento\n",
    "    - la dimostrazione di approssimazione continua ad essere valida se, invece di determinare l'ottimo per i primi $q$ jobs, determiniamo per loro una soluzione approssimata, cioè tale che $t \\leq (1+\\epsilon) \\cdot m^*$\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: C'è un algoritmo di programmazione dinamica che determina in tempo polinomiale uno scheduling per i primi $q$ jobs, scheduling con completion time $t \\leq (1+\\epsilon) \\cdot m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: esiste un PTAS per Min multiprocessor scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FULLY POLYNOMIAL TIME APPROXIMATION SCHEMES (FPTAS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- un algoritmo $A$ per un problema di ottimizzazione $\\pi \\in NPO$ è un FPTAS per $\\pi$ se, data un'istanza di input $x \\in I$ e un numero razionale $\\epsilon > 0$, ritorna una soluzione $(1+\\epsilon)$-approssimata (per MIN) o una soluzione $(1-\\epsilon)$-approssimata (per MAX) in tempo polinomiale rispetto alla taglia dell'istanza $x$ e rispetto a $1 \\over \\epsilon$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- FPTAS mantiene una buona complessità quando $\\epsilon$ decresce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FPTAS-knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- progr-dyn-knapsack-dual ha complessità pseudo-polinomiale: $O(n^2 \\cdot p_{max})$, dove $p_{max} = max \\{p_j\\}$ è il profitto massimo di un oggetto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cerchiamo di scalare i profitti originali ricavando profitti più piccoli in modo da ridurre la complessità ed ottenere un'approssimazione ancora migliore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. approssimiamo i profitti a multipli di $k$ per $k > 0$:\n",
    "$$ p'_i = \\lfloor {p_i \\over k} \\rfloor \\cdot k $$\n",
    "\n",
    "2. se $k$ è sufficientemente piccolo, profitti nuovi $p'_i$ approssimano bene profitti originali $p_i$, quindi soluzione ottima per i nuovi profitti approssima bene soluzione ottima per profitti originali\n",
    "\n",
    "3. scalando tutti i profitti $p'_i$ dividendo loro per $k$ otteniamo un'istanza equivalente con profitti più piccoli:\n",
    "$$ p'_i = { \\lfloor {p_i \\over k} \\rfloor \\cdot k \\over k } = \\lfloor {p_i \\over k} \\rfloor $$\n",
    "\n",
    "4. progr-dyn-knapsack-dual applicato a questa istanza porta ad una complessità più piccola"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- complessità: $O(n^2 \\cdot p'_{max}) = O(n^2 \\cdot {p_{max} \\over k})$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- approssimazione: errore al più $k$ per ogni oggetto scelto $\\rightarrow$ $n \\cdot k$ in totale\n",
    "- perciò: $m \\geq m^* - n \\cdot k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Idea: scegliamo $k$ sufficientemente grande per portare ad una complessità polinomiale e sufficientemente piccolo per fornire una buona approssimazione:\n",
    "$$ k = \\lfloor { \\epsilon \\cdot p_{max} \\over n } \\rfloor $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo FPTAS-knapsack:\n",
    "`BEGIN\n",
    "    - k = parte_intera_inf((epsilon*p_max) / n)\n",
    "    - trova soluzione ottima per istanza con profitti scalati p'_i = parte_intera_inf(p_i / k) usando progr-dyn-knapsack-dual e \n",
    "    - sia S insieme di oggetti ritornati\n",
    "    RETURN S\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$O(n^2 \\cdot p'_{max}) = O(n^2 \\cdot {p_{max} \\over k }) = O(n^2 \\cdot {p_{max} \\over {\\epsilon \\cdot p_{max} \\over n}}) = O({n^3 \\over \\epsilon})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approssimazione o errore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {m \\over m^*} \\geq {m^* - n \\cdot k \\over m^*} = 1 - {n \\cdot k \\over m^*} \\geq^* 1 - {n \\cdot k \\over p_{max}} \\geq 1 - { n \\cdot ({\\epsilon \\cdot p_{max} \\over n}) \\over p_{max} } = 1 - \\epsilon$$\n",
    "\n",
    "(\\*: $m^* \\geq p_{max}$)\n",
    "\n",
    "- perciò:\n",
    "\n",
    "$$ {m \\over m^*} \\geq 1 - \\epsilon $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- non abbiamo scalato i pesi, perchè non è garantito che tornando ai pesi originali la soluzione rimanga feasible (potrebbe eccedere peso $b$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: $m \\geq m^* - n \\cdot k$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- sia $S = \\{o_{j1},\\cdots,o_{jh}\\}$ e $S^* = \\{o_{i1}, \\cdots, o_{il}\\}$ una soluzione ottima, allora:\n",
    "$ m = p_{j1} + \\cdots + p_{jh} $ e $m^* = p_{i1} + \\cdots + p_{il}$\n",
    "\n",
    "- assumiamo per contraddizione che $m < m^* - n \\cdot k$, allora:\n",
    "\n",
    "$$ \\lfloor {p_{i1} \\over k} \\rfloor + \\cdots + \\lfloor {p_{il} \\over k} \\rfloor \\geq ({p_{i1} \\over k}-1) + \\cdots + ({p_{il} \\over k} - 1) \\geq {p_{i1} + \\cdots + p_{il} \\over k} - l \\geq {p_{i1} + \\cdots + p_{il} \\over k} - n =$$ \n",
    "$$= {m^* \\over k} -n >^* {m + n \\cdot k \\over k} - n = {m \\over k} = {p_{j1} + \\cdots + p_{jh} \\over k} \\geq \\lfloor {p_{j1} \\over k} \\rfloor + \\cdots + \\lfloor {p_{jh} \\over k} \\rfloor$$\n",
    "\n",
    "(\\*: dall'ipotesi: $m < m^* - n \\cdot k$)\n",
    "\n",
    "- ma questa è una contraddizione: $S^*$ sarebbe una soluzione STRETTAMENTE MIGLIORE di $S$ per l'istanza con profitti scalati, ma questo contraddice l'ottimalità di progr-dyn-knapsack-dual per l'istanza con profitti scalati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: FPTAS-knapsack è un FPTAS per Max 0-1 knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- complessità: $$ O({n^2 \\cdot p_{max} \\over k }) = O({n^2 \\cdot p_{max} \\over {\\epsilon \\cdot p_{max} \\over n}}) = O({n^3 \\over \\epsilon}) $$\n",
    "\n",
    "- approssimazione: $$ {m \\over m^*} \\geq^* {m^* - n \\cdot k \\over m^*} = 1 - {n \\cdot k \\over m^*} \\geq^{**} 1 - {n \\cdot k \\over p_{max}} \\geq 1 - {n \\cdot ({\\epsilon \\cdot p_{max} \\over n }) \\over p_{max}} = 1 - \\epsilon $$\n",
    "\n",
    "(\\*: da precedente **LEMMA**)\n",
    "\n",
    "(\\*\\*: $m^* \\geq p_{max} $)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $p_{max}$ è un lower bound ed $n \\cdot p_{max}$ è un upper bound per $m^*$, cioè: $p_{max} \\leq m^* \\leq n \\cdot p_{max}$\n",
    "- ma $p_{max}$ può essere molto più basso e $n \\cdot p_{max}$ molto più grande di $m^*$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## come migliorare i bounds per $m^*$ ?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- utilizziamo l'algoritmo $({1 \\over 2})$-approssimato modified-greedy\n",
    "- sia $m_{mg}$ la misura della sua soluzione ritornata\n",
    "- dato che abbiamo che ${m \\over m^*} \\geq {1 \\over 2}$ (approssimazione modified-greedy) e dato che $m_{mg} \\leq m^*$:\n",
    "$$ m_{mg} \\leq m^* \\leq 2 \\cdot m_{mg}$$\n",
    "- quindi, ora consideriamo $P' = \\lceil {2 \\cdot m_{mg} \\over k} \\rceil$ come profitto massimo in progr-dyn-knapsack-dual\n",
    "- settiamo parametro: $k = \\lfloor { \\epsilon \\cdot m_{mg} \\over n } \\rfloor$\n",
    "- eseguiamo progr-dyn-knapsack-dual modificato sull'istanza con i profitti scalati $p'_i = \\lfloor {p_i \\over k} \\rfloor$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Complessità\n",
    "$$ O({n \\cdot m_{mg} \\over k}) = O({n \\cdot m_{mg} \\over {\\epsilon \\cdot m_{mg} \\over n}}) = O({n^2 \\over \\epsilon})$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Approssimazione"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ {m \\over m^*} \\geq 1 - {n \\cdot k \\over m^*} \\geq^* 1 - {n \\cdot k \\over m_{mg}} \\geq 1 - { n \\cdot ({\\epsilon \\cdot m_{mg} \\over n}) \\over m_{mg} } = 1 - \\epsilon$$\n",
    "\n",
    "(\\*: $m_{mg} \\leq m^*$)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### New FPTAS-knapsack:\n",
    "`BEGIN\n",
    "    - computa m_mg eseguendo l'algoritmo modified-greedy e sia k = parte_intera_inf((epsilon*m_mg) / n)\n",
    "    - trova soluzione ottima per istanza con profitti scalati p'_i = parte_intera_inf(p_i / k) usando progr-dyn-knapsack-dual modificato* e\n",
    "    - sia S l'insieme di oggetti ritornato\n",
    "    RETURN S\n",
    "END`\n",
    "\n",
    "\\*: progr-dyn-knapsack-dual con P' = parte_intera_sup(2\\*m_mg / k)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# APPROCCI ALTERNATIVI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fino ad ora abbiamo considerato **approcci con performance garantite**:\n",
    "    - pro:\n",
    "        - approssimazione garantita per ogni input\n",
    "        - running time garantito per ogni input\n",
    "        - caso peggiore preso in considerazione\n",
    "    - contro:\n",
    "        - molti problemi non ammettono algoritmi con performance garantite o non sono ancora conosciuti\n",
    "        - a volte cattivo comportamente nella pratica"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ci sono approcci alternativi:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **restrizione sull'insieme delle istanze di input**:\n",
    "    - performance garantite solo su un sottoinsieme dell'input di interesse\n",
    "    - pro:\n",
    "        - permette di applicare l'approccio performance garantite su tale sottoinsieme\n",
    "    - contro:\n",
    "        - performance garantite solo su tale sottoinsieme"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **analisi probabilistica o media**:\n",
    "    - in generale, assumiamo distribuzione di probabilità delle istanze, essa valuta prestazioni medie o attese\n",
    "    - pro:\n",
    "        - può rilevare buon comportamento pratico di algoritmo\n",
    "        - metodo analitico basato su dimostrazioni matematiche\n",
    "    - contro:\n",
    "        - non ha performance garantite\n",
    "        - analisi spesso complessa\n",
    "        - distribuzione delle istanze di input spesso sconosciuta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **euristiche**:\n",
    "    - algoritmi con un buon comportamento pratico ma con performance non dimostrabili\n",
    "    - pro:\n",
    "        - buon comportamento pratico\n",
    "    - contro:\n",
    "        - performance non dimostrabili"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **algoritmi randomizzati**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Algoritmi randomizzati"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- fanno scelte randomiche durante la loro esecuzione\n",
    "- soluzioni ritornate differenti per esecuzioni differenti sulla stessa istanza di input"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- è dimostrato che, fissata qualsiasi istanza, il valore atteso delle performance è buono $\\rightarrow$ performance è buona con alta probabilità"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- pro: \n",
    "    - semplici e veloci\n",
    "- contro: \n",
    "    - incertezza del risultato per ogni istanza fissata\n",
    "    - scelte realmente randomiche sono impossibili (si possono però simulare)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- $m$ $\\rightarrow$ variabile random\n",
    "- $E(m)$ $\\rightarrow$ valore atteso di $m$ computato secondo le scelte randomiche dell'algoritmo"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Un algoritmo randomizzato $A$ è $r$-approssimante SE:\n",
    "    - ${E(m) \\over{m^*}} \\leq r$ (MIN)\n",
    "    - ${E(m) \\over{m^*}} \\geq r$ (MAX)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Max weighted cut:\n",
    "**INPUT**: grafo $G=(V,E)$, con peso non-negativo $w_{ij}$ per ogni arco $\\{v_i, v_j\\} \\in E$\n",
    "\n",
    "**SOLUZIONE**: partizione di $V$ in $2$ sottoinsiemi $V_1$ e $V_2$ tali che: $V_1 \\cap V_2 = \\emptyset$ e $V_1 \\cup V_2 = V$\n",
    "\n",
    "**MISURA**: peso del cut, cioè:\n",
    "$$\\sum_{\\{v_i, v_j\\} \\in E | v_i \\in V_1 \\wedge v_j \\in V_2} w_{ij} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo random-cut:\n",
    "`BEGIN\n",
    "\n",
    "    V_1 = Ø\n",
    "    V_2 = Ø\n",
    "    FOR i=1 TO n:\n",
    "        - metti v_i in V_1 con probabilità 1/2 indipendentemente dagli altri nodi, altrimenti in V_2\n",
    "    RETURN V_1 e V_2\n",
    "END`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- L'algoritmo è polinomiale"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: random-cut è un algoritmo $1 \\over 2$ - approssimato"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- Sia $x_{ij}$ la variabile randomica \"L'arco $\\{v_i, v_j\\}$ è nel cut\"\n",
    "- Allora: $$ m = \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot x_{ij}$$\n",
    "- Quindi: $$ E(m) = E(\\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot x_{ij}) = \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot E(x_{ij}) = \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot P(x_{ij} = 1) =$$\n",
    "$$= \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot P(( v_i \\in V_1 \\wedge v_j \\in V_2 )\\vee(V_i \\in V_2 \\wedge v_j \\in V_1)) = \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\cdot ({1 \\over 2} \\cdot {1 \\over 2} + {1 \\over 2} \\cdot {1 \\over 2}) = {1 \\over 2} \\cdot \\sum_{\\{v_i, v_j\\} \\in E} w_{ij} \\geq {m^* \\over 2} $$\n",
    "- Perciò: $${E(m) \\over m^*} \\geq {1 \\over 2}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Min weighted set cover: (recall)\n",
    "**INPUT**: universo $U = \\{o_1,\\cdots,o_n\\}$ di $n$ oggetti, famiglia $\\hat{S}=\\{S_1,\\cdots,S_h\\}$ di $h$ sottoinsiemi di $U$, costo intero $c_j$ associato ad ogni $S_j \\in \\hat{S}$ \n",
    "\n",
    "**SOLUZIONE**: cover di $U$, cioè sottofamiglia $\\hat{C} \\subseteq \\hat{S}$ tale che:\n",
    "$$ \\bigcup_{S_j \\in \\hat{C}} S_j = U $$\n",
    "\n",
    "**MISURA**: costo totale cover, cioè:\n",
    "$$ \\sum_{S_j \\in \\hat{C}} c_j $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **min wighted set cover**: identificare la più piccola sottocollezione di $S$, la cui unione è uguale all'universo $U$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$f$ = frequenza massima di un oggetto nei sottoinsiemi di $\\hat{S}$, ogni oggetto occorre in al più $f$ sottinsiemi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo Greedy per Min weighted set cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- nella scelta dei sottoinsiemi da inserire nel cover: \n",
    "    - non possiamo prendere in considerazione solo i costi (perchè potremmo coprire troppo pochi elementi di $U$) \n",
    "    - non possiamo prendere in considerazione solo il numero di oggetti coperti (perchè potremmo incorrere in un costo eccessivo)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- **scelta greedy**: ad ogni step scegliamo il sottoinsieme che ha costo minimo per nuovi oggetti coperti"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scelta Greedy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Ad un dato step $j$ nel quale in ordine l'algoritmo ha selezionato $j - 1$ sottoinsiemi $S_1,\\dots,S_{j-1}$, l'efficacia di un non scelto ancora sottoinsieme $S_k$ è definita come:\n",
    "$$ eff(S_k) = {{c_k} \\over { |S_k \\cap \\overline{C_{j-1}}| }} $$ dove:\n",
    "- $c_k$ = costo di $S_k$\n",
    "- $C_{j-1}$ = $(S_1 \\cup \\dots \\cup S_{j-1})$\n",
    "- $\\overline{C_{j-1}} = U \\backslash C_{j-1}$ (insieme di elementi che mancano nella soluzione)\n",
    "- (denominatore di $eff(S_k)$ = insieme di elementi che sto per inserire nella soluzione: numero di nuovi oggetti coperti)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Allo step $j$ scegliamo un sottoinsieme $S_j$ di efficacia minima, cioè, tale che:\n",
    "$eff(S_j) = min\\{eff(S_k) | S_k$ non è stato ancora scelto $\\}$ (cioè, con $c_k$ piccolo e denominatore grande)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo greedy-min-weighted-set-cover:\n",
    "`BEGIN\n",
    "\n",
    "    C = Ø\n",
    "    cap(C) = Ø\n",
    "    j = 1\n",
    "    WHILE C != U:\n",
    "        - Sia S_j un sottoinsieme di efficacia minima (S_j = min{eff(S_k) | S_k non scelto})\n",
    "        - metti S_j in cap(C)\n",
    "        - per ogni oggetto o_i in (S_j intersezione C barrato)*, sia price(o_i) = eff(S_j)\n",
    "        - C = C unione S_j\n",
    "        - j = j + 1\n",
    "    RETURN cap(C)\n",
    "END`\n",
    "\n",
    "\\*: elementi o_i che sono in S_j e NON sono in C; cioè, elementi appena scelti che non sono mai stati scelti prima: gli elementi che sto per andare a coprire"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: $$m = \\sum_{S_j \\in \\hat{C}} c_j = \\sum_{i=1}^{n} price(o_i)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- banale: la somma dei prezzi degli oggetti coperti nello step $j$ è $c_j$.\n",
    "\n",
    "(nello step $j$ abbiamo scelto l'insieme $S_j$ di efficacia minima, la somma dei $price(o_i)$ degli oggetti contenuti in $S_j$ è in totale $c_j$, dato che per definizione $price(o_i) =$ costo totale dell'insieme scelto diviso numero di oggetti che vado a coprire con l'insieme scelto: costo totale dell'insieme scelto è diviso tra gli oggetti scelti, sommando i costi dei singoli oggetti torniamo a $c_j$)\n",
    "\n",
    "- in altre parole, il costo totale è diviso tra gli oggetti coperti."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: \n",
    "\n",
    "Per ogni $j$, data qualsiasi scelta di sottoinsiemi $S_{j}^{'}, \\cdots, S_{t}^{'}$ che formano un cover con i sottoinsiemi $S_{1}, \\cdots, S_{j-1}$ scelti dall'algoritmo greedy all'inizio dello step $j$, per ogni oggetto $o_i$ non ancora coperto all'inizio dello step $j$, $price'(o_i) \\geq eff(S_j)$. \n",
    "\n",
    "Dove $S_j$ è il sottoinsieme scelto dall'algoritmo greedy allo step $j$, $eff(S_j)$ la sua efficacia, $price'(o_i)$ è l'efficacia del sottoinsieme $S_{l}^{'}$ che copre $o_i$ assumento che, partendo dallo step $j$, la scelta greedy è fatta solo tra i sottoinsiemi $S_{j}^{'}, \\cdots, S_{t}^{'}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**: \n",
    "\n",
    "- è sufficiente osservare che $eff(S_j)$ è il prezzo di copertura **minimo** per oggetto allo step $j$ e che, l'efficacia di un sottoinsieme non ancora scelto può solo incrementare durante gli steps.\n",
    "\n",
    "(dato che il costo del sottoinsieme è fissato, mentre alcuni ulteriori oggetti al suo interno possono essere coperti durante gli steps a causa della scelta di altri sottoinsiemi, numeratore ($c_k$) fissato, denominatore ($|S_k \\cap \\overline{C_{j-1}}|$) diminuisce $\\rightarrow$ $eff(S_j)$ aumenta)\n",
    "\n",
    "- Quindi il prezzo di $o_i$, cioè l'efficacia del sottoinsieme $S_{l}^{'}$ con $l \\geq j$ tra $S_{j}^{'}, \\cdots, S_{t}^{'}$ che lo copre, è almeno uguale a $eff(S_j)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**LEMMA**: sia $o_1, \\cdots, o_n$ gli oggetti listati nell'ordine del covering dell'algoritmo greedy, cioè, tale che gli oggetti coperti durante lo step $j$ sono listati dopo quelli coperti negli step precedenti e prima di quelli coperti negli step successivi, allora, per ogni $i$ tale che $1 \\leq i \\leq n$: \n",
    "$$ price(o_i) \\leq {{m^*} \\over {n - i + 1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "- consideriamo qualunque oggetto $o_i$ e sia $j$ lo step nel quale è coperto.\n",
    "- all'inizio dello step $j$, dato che i non ancora scelti sottoinsiemi di una soluzione ottima possono coprire tutti gli oggetti non coperti con costo totale al più $m^*$, DEVE esistere un sottoinsieme $S_k$ con efficacia al più ${{m^*} \\over {|\\overline{C_{j-1}}|}}$. \n",
    "\n",
    "Dove $\\overline{C_{j-1}}$ sono i sottoinsiemi di oggetti non ancora coperti all'inizio dello step $j$.\n",
    "\n",
    "- Infatti, se questo non è il caso, dato che il prezzo di $o_i$ è uguale all'efficacia $eff(S_j)$ del sottoinsieme $S_j$ scelto dall'algoritmo greedy, dal precedente lemma, per ogni possibile scelta dei sottoinsiemi rimanenti per completare il cover, cioè, per ogni possibile prezzo degli oggetti rimanenti:\n",
    "$$ \\sum_{o_i \\in \\overline{C_{j-1}}} price'(o_i) \\geq \\sum_{o_i \\in \\overline{C_{j-1}}} eff(S_j) >^* \\sum_{o_i \\in \\overline{C_{j-1}}} {{m^*} \\over { |\\overline{C_{j-1}}| }} = |\\overline{C_{j-1}}| \\cdot {{m^*} \\over { |\\overline{C_{j-1}}| }} = m^* $$\n",
    "\n",
    "\\*: \"al più\" negato $\\rightarrow$ prova per assurdo\n",
    "\n",
    "- una CONTRADDIZIONE all'ipotesi che esiste una scelta di sottoinsiemi che coprono i rimanenti oggetti con costo al più $m^*$.\n",
    "\n",
    "Quindi: $$price(o_i) \\leq {{m^*} \\over { |\\overline{C_{j-1}}| }}$$\n",
    "\n",
    "Ma: $|\\overline{C_{j-1}}| \\geq n - i + 1$ dato che $o_i, \\cdots, o_n \\in \\overline{C_{j-1}}$,\n",
    "\n",
    "E come conseguenza:\n",
    "$$ price(o_i) \\leq {{m^*} \\over {|\\overline{C_{j-1}}|}} \\leq {{m^*} \\over {n - i + 1}}$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**TEOREMA**: l'algoritmo greedy-min-weighted-set-cover è $H_n$-approssimante, dove $H_n = 1 + {1 \\over 2} + {1 \\over 3} + {1 \\over 4} + \\dots + {1 \\over n}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**RECAP**\n",
    "\n",
    "- serie armonica = $\\sum_{n=1}^{\\infty} {1 \\over n}$\n",
    "- forma generica: $$\\sum_{n=1}^{\\infty} {1 \\over {n^\\alpha}}$$\n",
    "- converge: Se $\\alpha > 1$\n",
    "- diverge: Se $ 0 < \\alpha \\leq 1$\n",
    "\n",
    "**FINE RECAP**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**DIMOSTRAZIONE**:\n",
    "\n",
    "$$ m = \\sum_{i=1}^{n} price(o_i) \\leq \\sum_{i=1}^{n} {{m^*} \\over {n - i + 1}} =^* m^* \\cdot ({1 \\over n} + {1 \\over {n - 1}} + {1 \\over {n - 2}} + \\dots + 1) = m^* \\cdot H_n $$\n",
    "\n",
    "Da cui:\n",
    "$${m \\over {m^*}} \\leq {H_n}^{**}$$\n",
    "\n",
    "\\*: $\\sum_{i=1}^{n} {{1} \\over {n - i + 1}} = ({1 \\over n} + {1 \\over {n - 1}} + {1 \\over {n - 2}} + \\dots + 1) = H_n$ ($H_n$ perchè anche se letto al contrario, la somma è comunque commutativa (l'ordine non importa))\n",
    "\n",
    "\\*\\*: ${{m} \\over {m^*}} \\leq {{m^* \\cdot H_n} \\over {m^*}} \\leq H_n$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTA**: per ogni $n > 1$, $ln(n+1) \\leq H_n \\leq ln(n) + 1$, quindi $r$ ha dipendenza logaritmica dalla dimensione dell'input."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Il rapporto di approssimazione dell'algoritmo greedy è almeno $H_n$.\n",
    "- La misura della soluzione ritornata dall'algoritmo greedy per qualche istanza è $H_n$ volte quella ottima."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Esercizi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0-1 Knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supponiamo di dover prendere un volo Lufthansa per Los Angeles. Il limite di peso imposto da Lufthansa è 23 kg. assumiamo che siamo interessati a portare i seguenti items: (item, weight, profit)\n",
    "\n",
    "![image.png](images/knapsack_1_part1.png)\n",
    "\n",
    "1. applica l'algoritmo greedy-knapsack per risolvere questa istanza del problema 0-1 knapsack (listando e facendo vedere tutti gli steps differenti)\n",
    "2. la soluzione cambia quando applichiamo l'algoritmo modified-greedy?\n",
    "3. computa la soluzione applicando l'algoritmo FPTAS-knapsack"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supponiamo di avere la seguente istanza del problema 0-1 knapsack, con la capacity dello knapsack uguale a 5 ($b = 5$): (item, weight, profit)\n",
    "\n",
    "![image.png](images/knapsack_2_part1.png)\n",
    "\n",
    "1. applica l'algoritmo progr-dyn-knapsack per risolvere questa istanza del problema 0-1 knapsack (riempi la tabella, ritorna la soluzione con il massimo profitto e lista gli items che sono inseriti nello knapsack in tale soluzione)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min set cover"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Consideriamo la seguente istanza del problema min-weighted set cover:\n",
    "    - $U = \\{1,2,3,4,5,6\\}$\n",
    "    - $S_1 = \\{1,6\\},\\\\\n",
    "      S_2 = \\{1,2,6\\},\\\\\n",
    "      S_3 = \\{1,4\\},\\\\\n",
    "      S_4 = \\{1,5\\},\\\\\n",
    "      S_5 = \\{1,3,5\\},\\\\\n",
    "      S_6 = \\{2,6\\}$\n",
    "    - $c_1 = 3,\\\\\n",
    "      c_2 = 4,\\\\\n",
    "      c_3 = 2,\\\\\n",
    "      c_4 = 3,\\\\\n",
    "      c_5 = 5,\\\\\n",
    "      c_6 = 2$\n",
    "1. applica l'algoritmo greedy-min-weighted-set-cover per risolvere l'istanza del problema (lista e mostra tutti gli steps differenti)\n",
    "2. computa la soluzione ottima dell'istanza del problema"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Min multiprocessor scheduling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Supponiamo di avere la seguente istanza del problema Min multiprocessor scheduling, con 3 CPU disponibili ($h=3$): (process, running time)\n",
    "\n",
    "![image.png](images/min_mprocessor_scheduling_part1.png)\n",
    "\n",
    "1. risolvi l'istanza del problema applicando l'algoritmo greedy di Graham\n",
    "2. risolvi l'istanza del problema applicando l'algoritmo ordered-greedy\n",
    "3. risolvi l'istanza del problema applicando l'algoritmo PTAS-scheduling, con valori differenti di $\\epsilon$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
