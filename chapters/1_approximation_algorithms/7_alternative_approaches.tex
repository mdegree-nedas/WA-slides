\section*{alternative approaches}
\addcontentsline{toc}{section}{alternative approaches}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{performance garantite}
\addcontentsline{toc}{subsection}{performance garantite}
\begin{flushleft}
	\begin{itemize}
		\item finora abbiamo considerato approcci con performance garantite
		\item pro:
		\begin{itemize}
			\item approssimazione e tempo di esecuzione garantiti per ogni istanza in input
			\item prende in considerazione il caso peggiore
		\end{itemize}
		\item contro:
		\begin{itemize}
			\item alcuni problemi non ammettono algoritmi con performance garantite
			\item per alcuni problemi non sono noti algoritmi con performance garantite
			\item a volte, cattivi comportamenti nella pratica
		\end{itemize}
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{restrizione dell'insieme delle istanze}
\addcontentsline{toc}{subsection}{restrizione dell'insieme delle istanze}
\begin{flushleft}
	\begin{itemize}
		\item performance garantite nel sottoinsieme delle istanze in input che sono significative o di interesse
		\item pro:
		\begin{itemize}
			\item permette di applicare nuovamente l'approccio con performance garantite
		\end{itemize}
		\item contro:
		\begin{itemize}
			\item performance garantite solo per il sottoinsieme scelto di istanze o per un caso particolare
		\end{itemize}
		\item esempio: metric TSP (con disequazioni triangolari)
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{media o analisi probabilistica}
\addcontentsline{toc}{subsection}{media o analisi probabilistica}
\begin{flushleft}
	\begin{itemize}
		\item in generale, assumendo una distribuzione di probabilit\'a dell'istanza, essa eguaglia la media o la performance attesa, alcune volte con alta probabilit\'a
		\item pro:
		\begin{itemize}
			\item pu\'o accorgersi di buoni comportamenti pratici dell'algoritmo
			\item \'e un metodo analitico, ovvero basato su dimostrazioni matematiche
		\end{itemize}
		\item contro:
		\begin{itemize}
			\item non ha performance garantite
			\item l'analisi \'e spesso complessa
			\item spesso la distribuzione delle istanze in input \'e sconosciuta
		\end{itemize}
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{euristiche}
\addcontentsline{toc}{subsection}{euristiche}
\begin{flushleft}
	\begin{itemize}
		\item algoritmi con un buon comportamento pratico ma solitamente con performance non dimostrabili
		\item pro:
		\begin{itemize}
			\item buon comportamento pratico
		\end{itemize}
		\item contro:
		\begin{itemize}
			\item performance spesso non dimostrabili
		\end{itemize}
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{algoritmi randomizzati}
\addcontentsline{toc}{subsection}{algoritmi randomizzati}
\begin{flushleft}
	\begin{itemize}
		\item effetuano scelte randomiche durante la computazione
		\item le soluzioni ritornate possono essere differenti per esecuzioni differenti sullo stesso input
		\item esse sono infatti variabili random (per ogni istanza vi sono diverse soluzioni, ciascuna restituita con una certa probabilit\'a determinata in accordo con le scelte randomiche dell'algoritmo)
		\item \'e mostrato che, fissata una qualsiasi istanza, il valore atteso delle performance \'e buono o la performance \'e buona con alta probabilit\'a (sempre in accordo con le scelte randomiche)
		\item pro:
		\begin{itemize}
			\item sono generalmente semplici
			\item sono veloci (sia analiticamente che in pratica)
		\end{itemize}
		\item contro:
		\begin{itemize}
			\item incertezza del risultato per ogni istanza fissata
			\item impossibilit\'a di fare scelte realmente randomiche (sebbene esse possano essere simulate)
		\end{itemize}
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{algoritmi randomizzati}
\addcontentsline{toc}{subsection}{algoritmi randomizzati}
\begin{flushleft}
	\begin{itemize}
		\item $m\rightarrow$ \'e una variabile randomica
		\item $E(m)\rightarrow$ \'e il valore atteso di $m$ calcolato in accordo con le scelte randomiche dell'algoritmo
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{definizione: algoritmi randomizzati e $r$-approssimazione}
\addcontentsline{toc}{subsection}{definizione: algoritmi randomizzati e $r$-approssimazione}
\begin{flushleft}
	\begin{itemize}
		\item un algoritmo randomizzato $A$ \'e $r$-approssimante se:
			$$\frac{E(m)}{m^*}\leq r\hspace{2cm}\text{(per }\min\text{)}$$
			$$\frac{E(m)}{m^*}\geq r\hspace{2cm}\text{(per }\max\text{)}$$
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{problema: max weighted cut}
\addcontentsline{toc}{subsection}{problema: max weighted cut}
\begin{flushleft}
	\begin{itemize}
		\item INPUT:
		\begin{itemize}
			\item grafo $G=(V,E)$
			\item peso non-negativo $w_{ij}>0$, $\forall\{v_i,v_j\}\in E$
		\end{itemize}
		\item SOLUZIONE: partizione di $V$ in 2 sottoinsiemi $V_1$ e $V_2$ tale che
			$$V_1\cap V_2=\emptyset\text{ e }V_1\cup V_2=V$$
		\item MISURA: peso del taglio, ovvero
			$$\sum_{\{v_i,v_j\}\in E\vert(v_i\in V_1\land v_j\in V_2)\lor(v_i\in V_2\land v_j\in V_1)}w_{ij}$$
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\newpage
\subsection*{algoritmo: Random-Cut}
\addcontentsline{toc}{subsection}{algoritmo: Random-Cut}
\begin{flushleft}
	\begin{algorithm}
		\caption{Random-Cut}
		\begin{algorithmic}
			\STATE $V_1=\emptyset$
			\STATE $V_2=\emptyset$
			\FOR{$i=1$ to $n$}
				\STATE inserisci $v_i$ in $V_1$ con probabilit\'a $\frac{1}{2}$ indipendentemente dagli altri nodi (oppure in $V_2$)
			\ENDFOR
			\RETURN $V_1$ e $V\setminus V_1$ ($\equiv V_2$)
		\end{algorithmic}
	\end{algorithm}
	\begin{itemize}
		\item chiaramente, l'algoritmo \'e polinomale
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{teorema: Random-Cut \'e $\frac{1}{2}$-approssimante}
\addcontentsline{toc}{subsection}{teorema: Random-Cut \'e $\frac{1}{2}$-approssimante}
\begin{flushleft}
	Random-Cut \'e $\frac{1}{2}$-approssimante \newline \\
	\textbf{dimostrazione:}
	\begin{itemize}
		\item sia $x_{ij}$ la variabile randomica "l'arco $\{v_i,v_j\}$" \'e nel taglio"
		\item allora
			$$m=\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot x_{ij}$$
		\item quindi
			$$E(m)=E(\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot x_{ij})=\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot E(x_{ij})=$$
			$$=\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot P(x_{ij}=1)=$$
			$$=\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot P((v_i\in V_1\land v_j\in V_2)\lor(v_i\in V_2\land v_j\in V_1))=$$
			$$=\sum_{\{v_i,v_j\}\in E}w_{ij}\cdot P(\frac{1}{2}\cdot\frac{1}{2}+\frac{1}{2}\cdot\frac{1}{2})=\frac{1}{2}\cdot\sum_{\{v_i,v_j\}\in E}w_{ij}\geq\frac{m^*}{2}$$
		\item dunque
			$$\frac{E(m)}{m^*}\geq\frac{1}{2}$$
	\end{itemize}
	\hfill$\square$
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{problema: min weighted set cover (gi\'a definito precedentemente)}
\addcontentsline{toc}{subsection}{problema: min weighted set cover (gi\'a definito precedentemente)}
\begin{flushleft}
	\begin{itemize}
		\item INPUT:
		\begin{itemize}
			\item un universo $U=\{o_1,o_2,\ldots,o_n\}$ di $n$ oggetti
			\item una famiglia $\hat{S}=\{S_1,S_2,\ldots,S_h\}$ di $h$ sottoinsiemi di $U$
			\item un costo intero $c_j$ associato ad ogni $S_j\in \hat{S}$
		\end{itemize}
		\item SOLUZIONE: un cover di $U$, ovvero una sottofamiglia $\hat{C}\subseteq\hat{S}$ tale che:
			$$\cup_{S_j\in\hat{C}}S_j=U$$
		\item MISURA: costo totale del cover, ovvero
			$$\sum_{S_j\in\hat{C}}c_j$$
	\end{itemize}
	\vspace{0.5cm}
	\begin{itemize}
		\item $f=$ frequenza massima di un oggetto nel sottoinsieme $\hat{S}$, ovvero ciasun oggetto occorre in al massimo $f$ sottoinsiemi
		\item dato un insieme di $n$ elementi $\{1,2,\ldots,n\}$ (chiamato universo) e una collezione $S$ di $m$ insiemi, la cui unione eguaglia l'universo, il problema del set cover consiste nell'identificare il pi\'u piccolo sottoinsieme di $S$ la cui unione eguaglia l'universo
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{algoritmo greedy per il problema min weighted set cover}
\addcontentsline{toc}{subsection}{algoritmo greedy per il problema min weighted set cover}
\begin{flushleft}
	\begin{itemize}
		\item \textbf{nota:} nella scelta dei sottoinsiemi da inserire nel cover:
		\begin{itemize}
			\item non possiamo considerare solo i costi, perch\'e in proporzione non potremmo coprire abbastanza elementi di $U$
			\item non possiamo considerare solo il numero di oggetti coperti, poich\'e potremmo incorrere in un costo eccessivo
		\end{itemize}
		\item \textbf{scelta greedy:} ad ogni step scegli il sottoinsieme avente costo minimo per il nuovo oggetto coperto
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{scelta greedy}
\addcontentsline{toc}{subsection}{scelta greedy}
\begin{flushleft}
	\begin{itemize}
		\item ad un dato step $j$ in cui nell'ordine l'algoritmo ha selezionato $j-1$ sottoinsiemi $S_1,\ldots,S_{j-1}$, l'efficacia di un sottoinsieme $S_k$ non ancora scelto \'e definito come:
			$$eff(S_k)=\frac{c_k}{\vert S_k\cap\overline{C_{j-1}}\vert}$$
		\item dove:
		\begin{itemize}
			\item $c_k=$ costo di $S_k$
			\item $C_{j-1}=$ $(S_1\cup\ldots\cup S_{j-1})$
			\item $\overline{C_{j-1}}=$ $U\setminus C_{j-1}$ (insieme degli elementi non ancora selezionati in $U$)
			\item $\vert S_k\cap\overline{C_{j-1}}\vert=$ insieme degli elementi in $S_k$ non ancora selezionati in $U$)
		\end{itemize}
		\item nello step $j$ scegli un sottoinsieme $S_j$ di efficacia minima, ovvero tale che
			$$eff(S_j)=\min\{eff(S_k)\text{ }\vert\ S_k \text{ non \'e stato ancora scelto}\}$$
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{algoritmo: Greedy-Min-Weighted-Set-Cover}
\addcontentsline{toc}{subsection}{algoritmo: Greedy-Min-Weighted-Set-Cover}
\begin{flushleft}
	\begin{algorithm}
		\caption{Greedy-Min-Weighted-Set-Cover}
		\begin{algorithmic}
			\STATE \color{gray} // C = insieme degli oggetti coperti \color{black}
			\STATE $C=\emptyset$
			\STATE \color{gray} // $\hat{C}$ = insieme dei sottoinsiemi scelti nel cover \color{black}
			\STATE $\hat{C}=\emptyset$
			\STATE $j=1$
			\WHILE{$C\neq U$}
				\STATE sia $S_j$ il sottoinsieme di efficacia minima
				\STATE $\hat{C}=\hat{C}\cup S_j$
				\STATE per ogni oggetto $o_i\in S_j\cap\overline{C}$, sia $price(o_i)=eff(S_j)$
				\STATE $C=C\cup S_j$
				\STATE $j=j+1$
			\ENDWHILE
			\RETURN $\hat{C}$
		\end{algorithmic}
	\end{algorithm}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{lemma: $m=\sum_{S_j\in\hat{C}}c_j=\sum_{i=1}^nprice(o_i)$}
\addcontentsline{toc}{subsection}{lemma: $m=\sum_{S_j\in\hat{C}}c_j=\sum_{i=1}^nprice(o_i)$}
\begin{flushleft}
	$$m=\sum_{S_j\in\hat{C}}c_j=\sum_{i=1}^nprice(o_i)$$
	\textbf{dimostrazione:}
	\begin{itemize}
		\item banale, inquanto la somma dei $price$ degli oggetti coperti durante lo step $j$ \'e proprio $c_j$
		\item in altre parole, il costo totale $c_k$ viene suddiviso tra gli oggetti coperti
	\end{itemize}
	\hfill$\square$
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{lemma: $price'(o_i)\geq eff(S_j)$}
\addcontentsline{toc}{subsection}{lemma: $price'(o_i)\geq eff(S_j')$}
\begin{flushleft}
	\begin{itemize}
		\item $\forall j$, data una qualunque scelta di sottoinsiemi $S_j',\ldots,S_t'$, che forma un cover con i sottoinsiemi $S_1,\ldots,S_{j-1}$ scelti dall'algoritmo greedy all'inizio dello step $j$
		\item $\forall o_i$ (oggetto) non ancora coperto all'inizio dello step $j$
			$$price'(o_i)\geq eff(S_j)$$
		dove:
		\begin{itemize}
			\item $S_j$ \'e il sottoinsieme scelto dall'algoritmo greedy allo step $j$
			\item $eff(S_j)$ \'e l'efficacia del sottoinsieme $S_j$
			\item $price'(o_i)$ \'e l'efficacia del sottoinsieme $S_l'$ che copre $o_i$ assumendo che, partendo dallo step $j$, la scelta greedy \'e effettuata solo tra i sottoinsiemi $S_j',\ldots,S_t'$
		\end{itemize}
	\end{itemize}
	\textbf{dimostrazione:}
	\begin{itemize}
		\item \'e sufficiente osservare che $eff(S_j)$ \'e il $min\text{ }covering\text{ }price$ per l'oggetto allo step $j$ 
		\item e che l'efficacia di un sottoinsieme non scelto pu\'o solo aumentare durante gli step successivi
		\item poich\'e il suo costo \'e fisso, ma alcuni altri oggetti possono essere coperti durante i successivi step (scelta di ulteriori sottoinsiemi)
		\item quindi il $price'(o_i)$, ovvero l'efficacia del sottoinsieme $S_l'$ ($eff(S_l')$) con $l\geq j$ tra $S_j',\ldots,S_t'$ che lo copre \'e almeno uguale a ($\geq$) $eff(S_j)$
	\end{itemize}
	\hfill$\square$
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{lemma: $price(o_i)\leq\frac{m^*}{n-i+1}$}
\addcontentsline{toc}{subsection}{lemma: $price(o_i)\leq\frac{m^*}{n-i+1}$}
\begin{flushleft}
	\begin{itemize}
		\item siano $o_1,\ldots,o_n$ gli oggetti elencati nell'ordine di covering dell'algoritmo
			greedy (ovvero tale che gli oggetti coperti durante lo step $j$ vegono elencati dopo
			quelli coperti negli step precedenti e prima di quelli coperti negli step successivi)
		\item allora
			$$price(o_i)\leq\frac{m^*}{n-i+1}\hspace{2cm}\forall i\text{, }1\leq i\leq n$$
	\end{itemize}
	\textbf{dimostrazione:}
	\begin{itemize}
		\item all'inizio dello step $j$, poich\'e gli insiemi non ancora scelti di una soluzione ottima possono coprire tutti gli oggetti non coperti con un costo generale al massimo pari a $m^*$:
		\item esiste un sottoinsieme $S_k$ di efficacia al massimo pari a
			$$\frac{m^*}{\vert\overline{C_{j-1}}\vert}$$
		dove $\overline{C_{j-1}}$ \'e i sottoinsieme di oggetti non ancora coperti all'inizio dello step $j$
		\item infatti, se non \'e questo il caso, dato che il $price(o_i)=eff(S_j)$ del sottoinsieme $S_j$ scelto dall'algoritmo greedy
		\item dal precedente lemma, per ogni possibile scelta di sottoinsiemi restanti per completare il cover, ovvero per ogni possibile $price$ degli oggetti rimanenti:
			$$\sum_{o_i\in\overline{C_{j-1}}}price'(o_i)\geq\sum_{o_i\in\overline{C_{j-1}}}eff(S_j)>\sum_{o_i\in\overline{C_{j-1}}}\frac{m^*}{\vert\overline{C_{j-1}}\vert}=\vert\overline{C_{j-1}}\vert\cdot\frac{m^*}{\vert\overline{C_{j-1}}\vert}=m^*$$
		\item \textbf{contraddizione:} all'ipotesi che esiste una scelta di sottoinsiemi che copre i restanti oggetti con un costo al massimo parti a $m^*$
		\item quindi:
			$$price(o_i)\leq\frac{m^*}{\vert\overline{C_{j-1}}\vert}$$
		\item ma $\vert\overline{C_{j-1}}\vert\geq n-i+1$ poich\'e $o_i,\ldots,o_n\in\overline{C_{j-1}}$ e dunque:
			$$price(o_i)\leq\frac{m^*}{n-i+1}$$
	\end{itemize}
	\hfill$\square$
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{teorema: Greedy-Min-Weighted-Set-Cover \'e $H_n$-approssimante}
\addcontentsline{toc}{subsection}{teorema: Greedy-Min-Weighted-Set-Cover \'e $H_n$-approssimante}
\begin{flushleft}
	l'algoritmo Greedy-Min-Weighted-Set-Cover \'e $H_n$-approssimante, con
	$H_n=1+\frac{1}{2}+\frac{1}{3}+\ldots+1$ \newline \\
	\textbf{dimostrazione:}
	\begin{itemize}
		\item[] $$m=\sum_{i=1}^nprice(o_i)\leq\sum_{i=1}^n\frac{m^*}{n-i+1}=m^*(\frac{1}{n}+\frac{1}{n-1}+\frac{1}{n-2}+\ldots+1)=m^*\cdot H_n$$
		\item da cui:
			$$\frac{m}{m^*}\leq H_n$$
	\end{itemize}
	\hfill$\square$
	\begin{itemize}
		\item \textbf{nota:} $\forall n>1\rightarrow \ln(n+1)\leq H_n\leq\ln(n)+1$
		\item quindi $r$ ha una dipendenza logaritmica dalla dimensione dell'input
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\subsection*{esempio: $H_n\cdot m^*$!}
\addcontentsline{toc}{subsection}{esempio: $H_n\cdot m^*$!}
\begin{flushleft}
	\begin{itemize}
		\item il rapporto di approssimazione dell'algoritmo greedy \'e almeno $H_n$
		\item considera infatti la seguente istanza:
		\begin{itemize}
			\item $S_1$: $1$ oggetto, costo $c_1=\frac{1}{n}$
			\item $S_2$: $1$ oggetto, costo $c_2=\frac{1}{n-1}$
			\item $S_3$: $1$ oggetto, costo $c_3=\frac{1}{n-2}$
			\item ...
			\item $S_n$: $1$ oggetto, costo $c_n=1$
			\item $S_{n+1}$: $n$ oggetti, costo $c_{n+1}=1+\epsilon$ (con $\epsilon>0$, arbitrariamente piccolo)
		\end{itemize}
		\item esecuzione:
		\begin{itemize}
			\item \textbf{step 1}:
			\begin{itemize}
				\item $eff(S_1)<eff(S_{n+1})=\frac{1}{n}<\frac{1+\epsilon}{n}$
				\item scelgo l'insieme di efficacia minima $S_1$
			\end{itemize}
			\item \textbf{step 2}:
			\begin{itemize}
				\item $eff(S_2)<eff(S_{n+1})=\frac{1}{n-1}<\frac{1+\epsilon}{n-1}$
				\item scelgo l'insieme di efficacia minima $S_2$
			\end{itemize}
			\item ...
			\item l'algoritmo \textbf{non} sceglier\'a mai il sottoinsieme $S_{n+1}$
		\end{itemize}
		\item quindi:
			$$m=\sum_{j=1}^n\frac{1}{j}=H_n$$
			$$m^*=1+\epsilon\hspace{2cm}\text{(con $\epsilon>0$, arbitrariamente piccolo)}$$
		\item dunque:
			$$\frac{m}{m^*}=\frac{H_n}{1+\epsilon}$$
		\item allora, per $\epsilon\rightarrow 0$:
			$$\frac{m}{m^*}\rightarrow H_n$$
		\item dunque la misura della soluzione restituita dall'algoritmo greedy, per alcune istanze,
			\'e $H_n$ volte quella ottima!
	\end{itemize}
\end{flushleft}

% $$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$$

\newpage
